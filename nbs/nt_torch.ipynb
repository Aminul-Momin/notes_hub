{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#torch.Tensor\" data-toc-modified-id=\"torch.Tensor-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>torch.Tensor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Instentiation-of-Tensor\" data-toc-modified-id=\"Instentiation-of-Tensor-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Instentiation of Tensor</a></span></li><li><span><a href=\"#Initiation-of-Tensor-using-Factory-Methods\" data-toc-modified-id=\"Initiation-of-Tensor-using-Factory-Methods-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Initiation of Tensor using Factory Methods</a></span></li><li><span><a href=\"#Random-Initiation-of-Tensor\" data-toc-modified-id=\"Random-Initiation-of-Tensor-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Random Initiation of Tensor</a></span></li><li><span><a href=\"#Types-and-Attributes\" data-toc-modified-id=\"Types-and-Attributes-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Types and Attributes</a></span></li><li><span><a href=\"#Indexing-and-Slicing\" data-toc-modified-id=\"Indexing-and-Slicing-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Indexing and Slicing</a></span></li><li><span><a href=\"#Tensor-Arithmatics\" data-toc-modified-id=\"Tensor-Arithmatics-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Tensor Arithmatics</a></span></li><li><span><a href=\"#Tensor-Addition\" data-toc-modified-id=\"Tensor-Addition-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Tensor Addition</a></span></li><li><span><a href=\"#Scalar-Multiplication\" data-toc-modified-id=\"Scalar-Multiplication-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Scalar Multiplication</a></span></li><li><span><a href=\"#Element-wise-Product/Hadamard-Product\" data-toc-modified-id=\"Element-wise-Product/Hadamard-Product-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Element-wise Product/Hadamard Product</a></span></li><li><span><a href=\"#Broadcasting\" data-toc-modified-id=\"Broadcasting-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Broadcasting</a></span></li><li><span><a href=\"#Usefull-Functions\" data-toc-modified-id=\"Usefull-Functions-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Usefull Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tensor.data_ptr(...)\" data-toc-modified-id=\"Tensor.data_ptr(...)-1.11.1\"><span class=\"toc-item-num\">1.11.1&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/tensors.html\" rel=\"nofollow\" target=\"_blank\"><code>Tensor.data_ptr(...)</code></a></a></span></li><li><span><a href=\"#torch.view(...)\" data-toc-modified-id=\"torch.view(...)-1.11.2\"><span class=\"toc-item-num\">1.11.2&nbsp;&nbsp;</span><code>torch.view(...)</code></a></span></li><li><span><a href=\"#torch.cat(...)\" data-toc-modified-id=\"torch.cat(...)-1.11.3\"><span class=\"toc-item-num\">1.11.3&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat\" rel=\"nofollow\" target=\"_blank\"><code>torch.cat(...)</code></a></a></span></li><li><span><a href=\"#-torch.stack(...)\" data-toc-modified-id=\"-torch.stack(...)-1.11.4\"><span class=\"toc-item-num\">1.11.4&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack\" rel=\"nofollow\" target=\"_blank\"> <code>torch.stack(...)</code></a></a></span></li><li><span><a href=\"#-torch.vstack(...)\" data-toc-modified-id=\"-torch.vstack(...)-1.11.5\"><span class=\"toc-item-num\">1.11.5&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.vstack\" rel=\"nofollow\" target=\"_blank\"> <code>torch.vstack(...)</code></a></a></span></li><li><span><a href=\"#-torch.hstack(...)\" data-toc-modified-id=\"-torch.hstack(...)-1.11.6\"><span class=\"toc-item-num\">1.11.6&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.hstack\" rel=\"nofollow\" target=\"_blank\"> <code>torch.hstack(...)</code></a></a></span></li><li><span><a href=\"#torch.unsqueeze()-/-torch.squeeze()\" data-toc-modified-id=\"torch.unsqueeze()-/-torch.squeeze()-1.11.7\"><span class=\"toc-item-num\">1.11.7&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze\" rel=\"nofollow\" target=\"_blank\"><code>torch.unsqueeze() / torch.squeeze()</code></a></a></span></li><li><span><a href=\"#torch.where(a,-b,-c)\" data-toc-modified-id=\"torch.where(a,-b,-c)-1.11.8\"><span class=\"toc-item-num\">1.11.8&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.where.html#torch.where\" rel=\"nofollow\" target=\"_blank\"><code>torch.where(a, b, c)</code></a></a></span></li><li><span><a href=\"#torch.max(...)-/-torch.min(...)\" data-toc-modified-id=\"torch.max(...)-/-torch.min(...)-1.11.9\"><span class=\"toc-item-num\">1.11.9&nbsp;&nbsp;</span><code>torch.max(...) / torch.min(...)</code></a></span></li><li><span><a href=\"#-torch.arange(...)\" data-toc-modified-id=\"-torch.arange(...)-1.11.10\"><span class=\"toc-item-num\">1.11.10&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange\" rel=\"nofollow\" target=\"_blank\"> <code>torch.arange(...)</code></a></a></span></li><li><span><a href=\"#-torch.linspace(...)\" data-toc-modified-id=\"-torch.linspace(...)-1.11.11\"><span class=\"toc-item-num\">1.11.11&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace\" rel=\"nofollow\" target=\"_blank\"> <code>torch.linspace(...)</code></a></a></span></li><li><span><a href=\"#-torch.logspace(...)\" data-toc-modified-id=\"-torch.logspace(...)-1.11.12\"><span class=\"toc-item-num\">1.11.12&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.logspace.html#torch.logspace\" rel=\"nofollow\" target=\"_blank\"> <code>torch.logspace(...)</code></a></a></span></li><li><span><a href=\"#torch.float(...)\" data-toc-modified-id=\"torch.float(...)-1.11.13\"><span class=\"toc-item-num\">1.11.13&nbsp;&nbsp;</span><code>torch.float(...)</code></a></span></li><li><span><a href=\"#torch.exp(...)/torch.sum(...)\" data-toc-modified-id=\"torch.exp(...)/torch.sum(...)-1.11.14\"><span class=\"toc-item-num\">1.11.14&nbsp;&nbsp;</span><code>torch.exp(...)</code>/<code>torch.sum(...)</code></a></span></li></ul></li><li><span><a href=\"#Matrix-Operation\" data-toc-modified-id=\"Matrix-Operation-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>Matrix Operation</a></span></li><li><span><a href=\"#Saving-&amp;-Loading\" data-toc-modified-id=\"Saving-&amp;-Loading-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>Saving &amp; Loading</a></span></li><li><span><a href=\"#GPU-Support\" data-toc-modified-id=\"GPU-Support-1.14\"><span class=\"toc-item-num\">1.14&nbsp;&nbsp;</span>GPU Support</a></span></li></ul></li><li><span><a href=\"#Training-Models:\" data-toc-modified-id=\"Training-Models:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training Models:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basics-of-Derivatives-in-PyTorch\" data-toc-modified-id=\"Basics-of-Derivatives-in-PyTorch-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Basics of Derivatives in PyTorch</a></span></li><li><span><a href=\"#Training-End-to-End-with-SGD\" data-toc-modified-id=\"Training-End-to-End-with-SGD-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Training End-to-End with SGD</a></span></li><li><span><a href=\"#Calculating-Gradients\" data-toc-modified-id=\"Calculating-Gradients-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Calculating Gradients</a></span></li><li><span><a href=\"#Stepping-With-a-Learning-Rate\" data-toc-modified-id=\"Stepping-With-a-Learning-Rate-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Stepping With a Learning Rate</a></span></li><li><span><a href=\"#An-End-to-End-SGD-with-(2nd-degree-poly-regression)\" data-toc-modified-id=\"An-End-to-End-SGD-with-(2nd-degree-poly-regression)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>An End-to-End SGD with (2nd degree poly regression)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Step-1:-Initialize-the-parameters\" data-toc-modified-id=\"Step-1:-Initialize-the-parameters-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Step 1: Initialize the parameters</a></span></li><li><span><a href=\"#Step-2:-Calculate-the-predictions\" data-toc-modified-id=\"Step-2:-Calculate-the-predictions-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Step 2: Calculate the predictions</a></span></li><li><span><a href=\"#Step-3:-Calculate-the-loss\" data-toc-modified-id=\"Step-3:-Calculate-the-loss-2.5.3\"><span class=\"toc-item-num\">2.5.3&nbsp;&nbsp;</span>Step 3: Calculate the loss</a></span></li><li><span><a href=\"#Step-4:-Calculate-the-gradients\" data-toc-modified-id=\"Step-4:-Calculate-the-gradients-2.5.4\"><span class=\"toc-item-num\">2.5.4&nbsp;&nbsp;</span>Step 4: Calculate the gradients</a></span></li><li><span><a href=\"#Step-5:-Step-the-weights.\" data-toc-modified-id=\"Step-5:-Step-the-weights.-2.5.5\"><span class=\"toc-item-num\">2.5.5&nbsp;&nbsp;</span>Step 5: Step the weights.</a></span></li><li><span><a href=\"#Step-6:-Repeat-the-process\" data-toc-modified-id=\"Step-6:-Repeat-the-process-2.5.6\"><span class=\"toc-item-num\">2.5.6&nbsp;&nbsp;</span>Step 6: Repeat the process</a></span></li><li><span><a href=\"#Step-7:-stop\" data-toc-modified-id=\"Step-7:-stop-2.5.7\"><span class=\"toc-item-num\">2.5.7&nbsp;&nbsp;</span>Step 7: stop</a></span></li></ul></li><li><span><a href=\"#Training-in-Using-Net:\" data-toc-modified-id=\"Training-in-Using-Net:-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Training in Using Net:</a></span></li></ul></li><li><span><a href=\"#torch.nn-/-torch.nn.functional\" data-toc-modified-id=\"torch.nn-/-torch.nn.functional-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/nn.html\" rel=\"nofollow\" target=\"_blank\">torch.nn</a> / <a href=\"https://pytorch.org/docs/stable/nn.functional.html\" rel=\"nofollow\" target=\"_blank\">torch.nn.functional</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Models</a></span></li><li><span><a href=\"#torch.nn.LossFunctioons\" data-toc-modified-id=\"torch.nn.LossFunctioons-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\" rel=\"nofollow\" target=\"_blank\">torch.nn.LossFunctioons</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#nn.MSELoss\" data-toc-modified-id=\"nn.MSELoss-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss\" rel=\"nofollow\" target=\"_blank\"><code>nn.MSELoss</code></a></a></span></li><li><span><a href=\"#nn.NLLLoss\" data-toc-modified-id=\"nn.NLLLoss-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss\" rel=\"nofollow\" target=\"_blank\"><code>nn.NLLLoss</code></a></a></span></li><li><span><a href=\"#nn.CrossEntropyLoss\" data-toc-modified-id=\"nn.CrossEntropyLoss-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\" rel=\"nofollow\" target=\"_blank\"><code>nn.CrossEntropyLoss</code></a></a></span></li><li><span><a href=\"#nn.BCELoss\" data-toc-modified-id=\"nn.BCELoss-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\" rel=\"nofollow\" target=\"_blank\"><code>nn.BCELoss</code></a></a></span></li></ul></li><li><span><a href=\"#Activation-Funcrions\" data-toc-modified-id=\"Activation-Funcrions-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Activation Funcrions</a></span><ul class=\"toc-item\"><li><span><a href=\"#torch.relu(...):\" data-toc-modified-id=\"torch.relu(...):-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span><code>torch.relu(...)</code>:</a></span></li><li><span><a href=\"#torch.tanh(...):\" data-toc-modified-id=\"torch.tanh(...):-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span><code>torch.tanh(...)</code>:</a></span></li><li><span><a href=\"#softmax(...):\" data-toc-modified-id=\"softmax(...):-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span><code>softmax(...)</code>:</a></span></li><li><span><a href=\"#torch.sigmoid(...):\" data-toc-modified-id=\"torch.sigmoid(...):-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span><code>torch.sigmoid(...)</code>:</a></span></li></ul></li></ul></li><li><span><a href=\"#torch.optim-(Optimizers)\" data-toc-modified-id=\"torch.optim-(Optimizers)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/optim.html\" rel=\"nofollow\" target=\"_blank\">torch.optim (Optimizers)</a></a></span></li><li><span><a href=\"#torch.utils.data\" data-toc-modified-id=\"torch.utils.data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/data.html\" rel=\"nofollow\" target=\"_blank\">torch.utils.data</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#torch.util.data.Dataset(...):\" data-toc-modified-id=\"torch.util.data.Dataset(...):-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\" rel=\"nofollow\" target=\"_blank\">torch.util.data.Dataset(...)</a>:</a></span></li><li><span><a href=\"#torch.util.data.DataLoader(...):\" data-toc-modified-id=\"torch.util.data.DataLoader(...):-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span><a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\" rel=\"nofollow\" target=\"_blank\">torch.util.data.DataLoader(...)</a>:</a></span></li><li><span><a href=\"#Primer-of-Dataset\" data-toc-modified-id=\"Primer-of-Dataset-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Primer of Dataset</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Create-your-Own-Dataset:\" data-toc-modified-id=\"Create-your-Own-Dataset:-5.3.0.1\"><span class=\"toc-item-num\">5.3.0.1&nbsp;&nbsp;</span>Create your Own Dataset:</a></span></li><li><span><a href=\"#Create-your-Own-Transformers:\" data-toc-modified-id=\"Create-your-Own-Transformers:-5.3.0.2\"><span class=\"toc-item-num\">5.3.0.2&nbsp;&nbsp;</span>Create your Own Transformers:</a></span></li><li><span><a href=\"#Compose-Several-Transformers:\" data-toc-modified-id=\"Compose-Several-Transformers:-5.3.0.3\"><span class=\"toc-item-num\">5.3.0.3&nbsp;&nbsp;</span>Compose Several Transformers:</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#torchvision\" data-toc-modified-id=\"torchvision-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span><a href=\"https://pytorch.org/vision/stable/index.html\" rel=\"nofollow\" target=\"_blank\">torchvision</a></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#torchvision.datasets(...):\" data-toc-modified-id=\"torchvision.datasets(...):-6.0.0.1\"><span class=\"toc-item-num\">6.0.0.1&nbsp;&nbsp;</span><a href=\"https://pytorch.org/vision/stable/datasets.html\" rel=\"nofollow\" target=\"_blank\">torchvision.datasets(...)</a>:</a></span></li><li><span><a href=\"#torchvision.transforms:\" data-toc-modified-id=\"torchvision.transforms:-6.0.0.2\"><span class=\"toc-item-num\">6.0.0.2&nbsp;&nbsp;</span><a href=\"https://pytorch.org/vision/stable/transforms.html\" rel=\"nofollow\" target=\"_blank\">torchvision.transforms</a>:</a></span></li><li><span><a href=\"#Pretrained-Torchvision-Models:\" data-toc-modified-id=\"Pretrained-Torchvision-Models:-6.0.0.3\"><span class=\"toc-item-num\">6.0.0.3&nbsp;&nbsp;</span><a href=\"https://pytorch.org/vision/stable/models.html#\" rel=\"nofollow\" target=\"_blank\">Pretrained Torchvision Models</a>:</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#End-to-End-Deep-Learning-with-PyTorch\" data-toc-modified-id=\"End-to-End-Deep-Learning-with-PyTorch-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>End to End Deep Learning with PyTorch</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style='color:red' size=5>Reference:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Introduction to Pytorch Code Examples by Stanford University](https://cs230.stanford.edu/blog/pytorch/)\n",
    "- [Classifying Images of Hand Signs by Stanford University](https://cs230.stanford.edu/blog/handsigns/)\n",
    "- [Named Entity Recognition Tagging by Stanford University](https://cs230.stanford.edu/blog/namedentity/)\n",
    "- [PYTORCH TUTORIALS by PYTORCH.org](https://pytorch.org/tutorials/)\n",
    "- []()\n",
    "- [PyTorch Notes](https://ikhlestov.github.io/pages/machine-learning/pytorch-notes/#work-with-cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Instentiation of Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L1 = [[1,2,3], [6,5,4], [7,8,9]]\n",
    "A1 = np.array(L1)\n",
    "\n",
    "T1_0 = torch.Tensor(L1)      # Tensor from Python List\n",
    "T1_1 = torch.Tensor(A1)      # Tensor from np.array()\n",
    "T1_2 = torch.Tensor(4,5) \n",
    "\n",
    "T1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initiation of Tensor using Factory Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T1_FM_0 = torch.tensor([1, 3, 2, 4])\n",
    "T1_FM_1 = torch.full((3,3), 2.0)\n",
    "T1_FM_2 = torch.ones((3,3))\n",
    "T1_FM_3 = torch.eye(3)\n",
    "\n",
    "print(T1_FM_0, T1_FM_1, T1_FM_2, T1_FM_3, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T1_stk_1 = torch.stack((T1_FM_1, T1_FM_3))\n",
    "T1_stk_2 = torch.stack((T1_FM_1, T1_FM_2, T1_FM_3), dim=1)\n",
    "\n",
    "print(T1_stk_1, T1_stk_2, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T1_cat_1 = torch.cat([T1_FM_1, T1_FM_2], dim=0)\n",
    "T1_cat_2 = torch.cat([T1_FM_1, T1_FM_2], dim=1)\n",
    "\n",
    "print(T1_cat_1, T1_cat_2, sep='\\n\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Initiation of Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T1_RN_0 = torch.randint(1,10,(5,))\n",
    "T1_RN_1 = torch.randint(1,10,(3,3), dtype=torch.float32)\n",
    "T1_RN_2 = torch.randn(5, 3)\n",
    "T1      = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "T1      = torch.from_numpy(np.random.rand(5, 3)).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(T1_RN_0, T1_RN_1, T1_RN_2, T1, T1, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Types and Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|Data type |Tensor|\n",
    "|----------|------|\n",
    "|32-bit floating point|\ttorch.FloatTensor|\n",
    "|64-bit floating point|\ttorch.DoubleTensor|\n",
    "|16-bit floating point|\ttorch.HalfTensor|\n",
    "|8-bit integer (unsigned)|torch.ByteTensor|\n",
    "|8-bit integer (signed)|torch.CharTensor|\n",
    "|16-bit integer (signed)|torch.ShortTensor|\n",
    "|32-bit integer (signed)|torch.IntTensor|\n",
    "|64-bit integer (signed)|torch.LongTensor|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "2\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "T2 = torch.full([3,3], 3.0)\n",
    "print(T2.shape, T2.ndim, T2.data, T2.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "2\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(T2.size(), T2.ndimension(), T2.numel(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "None\n",
      "None\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(T2.data, T2.grad_fn, T2.grad, T2.is_leaf, T2.requires_grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ßT2_np = T2.numpy()\n",
    "T2 = torch.from_numpy(T2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[11,21,31],'b':[12,22,312]})\n",
    "new_tensor = torch.from_numpy(df.values)\n",
    "\n",
    "df.values, df.values.dtype, new_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T2_one_elm_tensor = torch.tensor([2.0])\n",
    "T2_one_elm_tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Error: only one element tensors can be converted to Python scalars\n",
    "# T2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can use rectangular brackets to access the different elements of the tensor. The correspondence between the rectangular brackets and the list and the rectangular representation is shown in the following figure for a 3X3 tensor:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2index1.png\" width=500 alt=\"Matrix Structure Introduce\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2index.png\" width=\"500\" alt=\"Example of Matrix Index\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(A[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2_index2.png\" width=\"500\" alt=\"Example of Matrix Index\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2sliceing.png\" width=\"500\" alt=\"Example of Matrix Index and Slicing\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(A[0, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2slicing2.png\" width=\"500\" alt=\"Example of Matrix Index and Slicing\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(A[1:3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(A[1:3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tensor Arithmatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tensor Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2add.png\" width=\"500\" alt=\"Tensor Addition in 2D\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[1, 0],[0, 1]]) \n",
    "Y = torch.tensor([[2, 1],[1, 2]])\n",
    "X_plus_Y = X + Y\n",
    "print(X_plus_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scalar Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Multiplying a tensor by a scalar is identical to multiplying a matrix by a scaler. If you multiply the matrix <b>Y</b> by the scalar 2, you simply multiply every element in the matrix by 2 as shown in the figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2scaller_mult.png\" width=\"500\" alt=\"The product of tensor and scalar\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Y = torch.tensor([[2, 1], [1, 2]]) \n",
    "two_Y = 2 * Y\n",
    "print(two_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Element-wise Product/Hadamard Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Multiplication of two tensors corresponds to an element-wise product or Hadamard product.  Consider matrix the <b>X</b> and <b>Y</b> with the same size. The Hadamard product corresponds to multiplying each of the elements at the same position, that is, multiplying elements with the same color together. The result is a new matrix that is the same size as matrix <b>X</b> and <b>Y</b> as shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " <a><img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.2tensor_pruduct.png\" width=500 align=\"center\"> </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[1, 0], [0, 1]])\n",
    "Y = torch.tensor([[2, 1], [1, 2]]) \n",
    "X_times_Y = X * Y\n",
    "print(X_times_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1);\n",
    "pred = torch.randn((4,))\n",
    "pred.sigmoid()\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xb = torch.randn((4,3)); xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(xb.sigmoid(), xb[0].sigmoid(), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = torch.randint(0,3,(4,3))\n",
    "inputs = xb.sigmoid()\n",
    "print(targets, inputs, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fltr = -torch.where(targets==1, inputs, 1-inputs).log(); fltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Binary Cross Entropy\n",
    "bce = -torch.where(targets==1, inputs, 1-inputs).log().mean(); bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L1 = [x.mean() for x in fltr]; L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L2 = torch.tensor(L1).mean(); L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Usefull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T7_0 = torch.randperm(6)\n",
    "T7_1 = torch.randint(0,5,(4,4))\n",
    "\n",
    "print(T7_0, T7_1, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [`Tensor.data_ptr(...)`](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T7_0.data_ptr(), id(T7_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.view(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(T7_0.view(-1,8), T7_0.view(4,4), T7_0.view(8,-1), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T_7_2 = torch.linspace(-1, 1, 10).view(-1, 1); T_7_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  [`torch.cat(...)`](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concate2 = torch.cat([T7_0, T7_0], dim=0)\n",
    "concate1 = torch.cat([T7_0, T7_0], dim=1)\n",
    "\n",
    "concate1, concate2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.stack(...)`](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# accs = [10.0, 5.0, 7.0]\n",
    "accs = [torch.tensor(10.0), torch.tensor(5.0), torch.tensor(7.0)]\n",
    "stk = round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.vstack(...)`](https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.vstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.hstack(...)`](https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.hstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  [`torch.unsqueeze() / torch.squeeze()`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unsqz = T7_0.unsqueeze(1)\n",
    "print(unsqz, unsqz.squeeze(), T7_1.unsqueeze(1), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  [`torch.where(a, b, c)`](https://pytorch.org/docs/stable/generated/torch.where.html#torch.where)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the same as running the list comprehension \n",
    " - ``` python\n",
    "[b[i] if a[i] else c[i] for i in range(len(a))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- ``` python\n",
    "xarr = torch.tensor([1.1, 1.2, 1.3, 1.4, 1.5])\n",
    "yarr = torch.tensor([2.1, 2.2, 2.3, 2.4, 2.5])\n",
    "cond = torch.tensor([True, False, True, True, False])\n",
    "result = [(x if c else y)\n",
    "          for x, y, c in zip(xarr, yarr, cond)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "L7_0 = [0]*5 + [1]*5\n",
    "shuffle(L7_0)\n",
    "targets = torch.tensor(L7_0, dtype=torch.float32)\n",
    "shuffle(L7_0)\n",
    "predictions = torch.tensor(T7_2, dtype=torch.float32)\n",
    "# predictions = torch.randperm(5, dtype=torch.float32)\n",
    "whr = torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "print(targets, predictions, whr, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.max(...) / torch.min(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T7_2 = torch.randint(-5, 5, (9,)).float().view(-1,3)\n",
    "\n",
    "print(\n",
    "    T7_2, T7_2.max(1), \n",
    "    T7_2.max(torch.tensor([2])), \n",
    "    T7_2.min(torch.tensor([0.0])), sep='\\n\\n')\n",
    "\n",
    "type(T7_2.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = torch.tensor([[2,5,0]])\n",
    "value, index = z.max(1)\n",
    "value, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.arange(...)`](https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* `arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a1 = torch.arange(-1, 1.01, 0.5)\n",
    "a2 = torch.arange(-1, 0.99, 0.5)\n",
    "a3 = torch.arange(-1, 1, 0.5)\n",
    "\n",
    "print(a1, a2, a3, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.linspace(...)`](https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* `linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l1 = torch.linspace(-1, 1, 5)\n",
    "l2 = torch.linspace(-1, 1.1, 5)\n",
    "l3 = torch.linspace(-1, .99, 5)\n",
    "\n",
    "print(l1, l2, l3, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [ `torch.logspace(...)`](https://pytorch.org/docs/stable/generated/torch.logspace.html#torch.logspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.logspace(start=-10, end=10, steps=5)\n",
    "torch.logspace(start=0.1, end=1.0, steps=5)\n",
    "torch.logspace(start=2, end=2, steps=1, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.float(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.exp(...)`/`torch.sum(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(torch.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return (x.exp()/(x.exp().sum(-1, keepdim=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-24.5198, -40.3251, -10.6257,   3.2256],\n",
       "        [ 25.0067,   6.4096,   3.9762,   5.7944],\n",
       "        [ -1.3002, -21.8870,  -2.8411,   7.4455],\n",
       "        [ 30.7034,  12.0852,   7.9834,   8.9524],\n",
       "        [ -4.8147,   1.2925,  -0.3343,  -1.8650],\n",
       "        [-11.4197, -11.3090,  -4.6375,  -1.9637]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(42);\n",
    "X = torch.randn((6,3))*10\n",
    "W = torch.randn(3, 4)\n",
    "Z = X@W\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9197e-13, 1.2195e-19, 9.6485e-07, 1.0000e+00],\n",
       "        [1.0000e+00, 8.3828e-09, 7.3550e-10, 4.5313e-09],\n",
       "        [1.5911e-04, 1.8237e-13, 3.4081e-05, 9.9981e-01],\n",
       "        [1.0000e+00, 8.2078e-09, 1.3579e-10, 3.5783e-10],\n",
       "        [1.7940e-03, 8.0559e-01, 1.5835e-01, 3.4266e-02],\n",
       "        [7.3160e-05, 8.1722e-05, 6.4525e-02, 9.3532e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts = Z.exp()/Z.exp().sum(-1, keepdim=True); acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9197e-13, 1.2195e-19, 9.6485e-07, 1.0000e+00],\n",
       "        [1.0000e+00, 8.3828e-09, 7.3549e-10, 4.5313e-09],\n",
       "        [1.5911e-04, 1.8237e-13, 3.4081e-05, 9.9981e-01],\n",
       "        [1.0000e+00, 8.2078e-09, 1.3579e-10, 3.5783e-10],\n",
       "        [1.7940e-03, 8.0559e-01, 1.5835e-01, 3.4266e-02],\n",
       "        [7.3160e-05, 8.1722e-05, 6.4525e-02, 9.3532e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_acts = torch.softmax(Z, dim=1); sm_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sm_score = softmax(acts); sm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sm_score.sum(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Matrix Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also apply matrix multiplication to two tensors, if you have learned linear algebra, you should know that in the multiplication of two matrices order matters. This means if <i>X * Y</i> is valid, it does not mean <i>Y * X</i> is valid. The number of columns of the matrix on the left side of the multiplication sign must equal to the number of rows of the matrix on the right side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, let us create a tensor <code>X</code> with size 2X3. Then, let us create another tensor <code>Y</code> with size 3X2. Since the number of columns of <code>X</code> is equal to the number of rows of <code>Y</code>. We are able to perform the multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use <code>torch.mm()</code> for calculating the multiplication between tensors with different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1],\n",
      "        [1, 0, 1]])\n",
      "\n",
      "tensor([[ 1,  1],\n",
      "        [ 1,  1],\n",
      "        [-1,  1]])\n",
      "\n",
      "tensor([[0, 2],\n",
      "        [0, 2]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "B = torch.tensor([[1, 1], [1, 1], [-1, 1]])\n",
    "A_times_B = torch.mm(A,B) # A @ B\n",
    "\n",
    "print(A, B, A_times_B, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True],\n",
       "         [True, True],\n",
       "         [True, True]]),\n",
       " tensor([[True, True],\n",
       "         [True, True],\n",
       "         [True, True]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(A,0,1) == torch.t(A), torch.t(A) == A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[110],\n",
       "        [ 40]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4], [2, 1]])\n",
    "w = torch.tensor([10, 20])\n",
    "b = torch.tensor([0.15])\n",
    "x@w.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2675]) tensor([0.2675]) tensor([0.5665]) tensor([0.5665])\n"
     ]
    }
   ],
   "source": [
    "wx = torch.dot(x, w) + b\n",
    "wx2 = x@w.T + b\n",
    "\n",
    "a = wx.sigmoid()\n",
    "a2 = torch.sigmoid(wx)\n",
    "print(wx, wx2, a, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Saving & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "torch.save(model.state_dict(), 'data/test_model_saving.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a new linear regression model object\n",
    "model_prebuilt = nn.Linear(1,1)\n",
    "\n",
    "# Assign the best model to model_best\n",
    "model_param = torch.load('data/test_model_saving.pt')\n",
    "model_prebuilt.load_state_dict(model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.cuda.HalfTensor(5, 3).uniform_(-1, 1)\n",
    "y = torch.cuda.HalfTensor(3, 5).uniform_(-1, 1)\n",
    "torch.matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "x = x.cuda(device=0)\n",
    "print(x)\n",
    "x = x.cpu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "x = x.cuda(device=0)\n",
    "print(x)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.unsqueeze(0).expand(30, 5, 3)\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))\n",
    "x = x.contiguous()\n",
    "print('Contiguity : %s ' % (x.is_contiguous()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Basics of Derivatives in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0)\n",
    "print(x, x.requires_grad, x.grad, x.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = x**2\n",
    "print(y, y.requires_grad, y.grad, y.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x, x.requires_grad, x.grad, x.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b style='color:red'> Notes: </b>\n",
    "- **x** holds derivatives of **y** with respect to **x** at **x**, **$\\frac{dy}{dx}(x)$**\n",
    "- **x** does not hold any **gradient function**\n",
    "- **y** holds **gradient function**\n",
    "- **y** does not hold any derivative, **$\\frac{dy}{dx}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y, y.requires_grad, y.retain_grad(), y.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w = torch.tensor([1.0, 2.0, 2.0], requires_grad=True)\n",
    "y = w**2\n",
    "# y.backward()     # ERRORS !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y, y.requires_grad, y.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b style='color:red'> Notes: </b>\n",
    "- While `x.requires_grad` (a attribute of independent variavle **x**) is set true, then `y.requires_grad` is automaticaly set true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1 = torch.tensor([2.0], requires_grad=True)\n",
    "x2 = torch.tensor([3.0], requires_grad=True)\n",
    "z = x1*x2 + 2*x1*x2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(z, z.requires_grad, z.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(x1.grad, x2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "TXEHwjbKJG87"
   },
   "source": [
    "### Training End-to-End with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tensor = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n",
    "    x = torch.linspace(min,max)\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(x,f(x))\n",
    "    if tx is not None: ax.set_xlabel(tx)\n",
    "    if ty is not None: ax.set_ylabel(ty)\n",
    "    if title is not None: ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9257,
     "status": "ok",
     "timestamp": 1598558695948,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "RLyB56e5JG8-"
   },
   "outputs": [],
   "source": [
    "def f(x): return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9193,
     "status": "ok",
     "timestamp": 1598558695951,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "PCoHvvl7JG9C",
    "outputId": "53cc1dce-038c-48e8-da6c-941f4d4f8840"
   },
   "outputs": [],
   "source": [
    "# plot_function(f, 'x', 'x**2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9311,
     "status": "ok",
     "timestamp": 1598558696095,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "2KERGFDUJG9F",
    "outputId": "8927eb75-6560-4d0c-90cd-73504756acbf"
   },
   "outputs": [],
   "source": [
    "plot_function(f, 'x', '$x^2$')\n",
    "plt.scatter(-1.5, f(-1.5), color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "4YEv47GsJG9N"
   },
   "source": [
    "### Calculating Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9266,
     "status": "ok",
     "timestamp": 1598558696096,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "_4Vd9FsQJG9P",
    "outputId": "7ade16af-35c5-46c1-dff2-c0c864d9d1fc"
   },
   "outputs": [],
   "source": [
    "xt = tensor(3.).requires_grad_(); xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9211,
     "status": "ok",
     "timestamp": 1598558696098,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "0-jt6gaxJG9S",
    "outputId": "bae8103a-95f9-421e-a13d-1db03eac686d"
   },
   "outputs": [],
   "source": [
    "yt = f(xt)\n",
    "yt #; yt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9161,
     "status": "ok",
     "timestamp": 1598558696100,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "-KmkswC8JG9X",
    "outputId": "7ac04040-8962-4633-c26e-9d65088a540e"
   },
   "outputs": [],
   "source": [
    "yt.backward(); yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9123,
     "status": "ok",
     "timestamp": 1598558696101,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "K0DujGlwJG9c",
    "outputId": "3301784f-5af9-4dc5-9137-565a1d21f4c7"
   },
   "outputs": [],
   "source": [
    "xt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9107,
     "status": "ok",
     "timestamp": 1598558696109,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "3qBztFIbJG9e",
    "outputId": "09c161f9-e8cf-4d2b-8b52-0bdd53ea833e"
   },
   "outputs": [],
   "source": [
    "xt = tensor([3.,4.,10.]).requires_grad_()\n",
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9078,
     "status": "ok",
     "timestamp": 1598558696110,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "GtYP7DImJG9j",
    "outputId": "201e7192-7fd7-40f6-ca42-31c26374999d"
   },
   "outputs": [],
   "source": [
    "def f(x): return (x**2).sum()\n",
    "\n",
    "yt = f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9052,
     "status": "ok",
     "timestamp": 1598558696111,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "mKWTa13tJG9n",
    "outputId": "a76e0e10-03c5-4887-8640-c9fcbefe6a1a"
   },
   "outputs": [],
   "source": [
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "7rsTa5fOJG9w"
   },
   "source": [
    "### Stepping With a Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "GGEp-drVJG9w"
   },
   "source": [
    "### An End-to-End SGD with (2nd degree poly regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8990,
     "status": "ok",
     "timestamp": 1598558696112,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "e4hUvT3SJG9w",
    "outputId": "e599aa9a-ced9-4a79-91b6-01bd1f835ffc"
   },
   "outputs": [],
   "source": [
    "time = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9194,
     "status": "ok",
     "timestamp": 1598558696346,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "gvBK4aOXJG9y",
    "outputId": "edd8dc82-1c1c-4d92-a2c8-7fa99ae8e1b4"
   },
   "outputs": [],
   "source": [
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(time, speed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9171,
     "status": "ok",
     "timestamp": 1598558696347,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "Bn5r-5ygJG91"
   },
   "outputs": [],
   "source": [
    "# Predictor, Y_hat\n",
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9151,
     "status": "ok",
     "timestamp": 1598558696348,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "gsFq3vVlJG95"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def mse(preds, targets): return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "ZQdzA7i-JG9_"
   },
   "source": [
    "#### Step 1: Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9136,
     "status": "ok",
     "timestamp": 1598558696350,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "KwmSNvuIJG-A",
    "outputId": "249a3f15-0660-407d-8aad-5942e7ad011e"
   },
   "outputs": [],
   "source": [
    "params = torch.randn(3).requires_grad_(); params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9090,
     "status": "ok",
     "timestamp": 1598558696350,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "Dphufgd3a4Om"
   },
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9079,
     "status": "ok",
     "timestamp": 1598558696351,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "LaxkxL0CJG-C"
   },
   "outputs": [],
   "source": [
    "orig_params = params.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "LANZL-myJG-M"
   },
   "source": [
    "#### Step 2: Calculate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9066,
     "status": "ok",
     "timestamp": 1598558696352,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "sGMpV7tEJG-N"
   },
   "outputs": [],
   "source": [
    "preds = f(time, params) ## W = params, time = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9210,
     "status": "ok",
     "timestamp": 1598558696510,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "n6wS3uBLJG-P"
   },
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, preds.detach().numpy(), color='red')\n",
    "    ax.set_ylim(-300,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9471,
     "status": "ok",
     "timestamp": 1598558696790,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "Jpu5lsGaJG-R",
    "outputId": "0ebcf629-3745-48db-b1e4-d0f442ce00b3"
   },
   "outputs": [],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "9mCz8pPiJG-U"
   },
   "source": [
    "#### Step 3: Calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9425,
     "status": "ok",
     "timestamp": 1598558696791,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "1LjCOR-AJG-U",
    "outputId": "278e399e-8fd6-4cdb-ee08-4f843324ae33"
   },
   "outputs": [],
   "source": [
    "loss = mse(preds, speed) ## speed == target (y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "uuFXUbf5JG-W"
   },
   "source": [
    "#### Step 4: Calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9327,
     "status": "ok",
     "timestamp": 1598558696792,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "d-IjikhdJG-W",
    "outputId": "488dcc58-af63-467c-cdf5-d2917515ab30"
   },
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1598558696793,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "_RxJS9YmJG-Y",
    "outputId": "6ae85378-4822-4596-c277-ada2f2c3d09a"
   },
   "outputs": [],
   "source": [
    "params.grad * 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9157,
     "status": "ok",
     "timestamp": 1598558696794,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "byWMl_4iJG-a",
    "outputId": "3808a6bd-5366-43af-d027-1995c190bde6"
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9119,
     "status": "ok",
     "timestamp": 1598558696794,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "FuW323IlA0Ux",
    "outputId": "64839f65-1786-425b-c05a-dbd44a55fafe"
   },
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9090,
     "status": "ok",
     "timestamp": 1598558696795,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "J_UsHlEoB4wf",
    "outputId": "26e38f3c-a0f5-4cd4-dd62-d7e782706a65"
   },
   "outputs": [],
   "source": [
    "params.data #; type(params.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "yM4LDt3EJG-f"
   },
   "source": [
    "#### Step 5: Step the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9062,
     "status": "ok",
     "timestamp": 1598558696796,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "8Yrkm3anJG-f"
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9026,
     "status": "ok",
     "timestamp": 1598558696797,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "IWNjDz6KXj3p",
    "outputId": "40c64d26-bd47-442c-8270-2cb62b6146de"
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8999,
     "status": "ok",
     "timestamp": 1598558696800,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "yiLlPi-OJG-h",
    "outputId": "8c6c135a-1c16-405c-d7b7-8c362c8fd80a"
   },
   "outputs": [],
   "source": [
    "preds = f(time, params)\n",
    "mse(preds, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9209,
     "status": "ok",
     "timestamp": 1598558697040,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "NSwOBMBdJG-j",
    "outputId": "020fbc81-290c-4598-d531-1148caaa941b"
   },
   "outputs": [],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9186,
     "status": "ok",
     "timestamp": 1598558697041,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "saWJ0hn0JG-l"
   },
   "outputs": [],
   "source": [
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(\"loss = \", loss.item(), \";\\t\\t params = \", params)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "-0kfQECPJG-o"
   },
   "source": [
    "#### Step 6: Repeat the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9164,
     "status": "ok",
     "timestamp": 1598558697052,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "FNjLKvqJJG-p",
    "outputId": "660d810f-dade-4830-d043-0aa9d1c2c362"
   },
   "outputs": [],
   "source": [
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9136,
     "status": "ok",
     "timestamp": 1598558697053,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "ghBVUdt9YURl",
    "outputId": "a85ba05b-fb30-4f8f-c63a-35d405518fff"
   },
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9104,
     "status": "ok",
     "timestamp": 1598558697054,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "qepK9tLmJG-q",
    "outputId": "3854e11d-fc06-4eb8-9cb0-4bdf73c8e248"
   },
   "outputs": [],
   "source": [
    "params = orig_params.detach().requires_grad_(); params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9980,
     "status": "ok",
     "timestamp": 1598558697955,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "EoGLY08GJG-u",
    "outputId": "fcb0b7a1-0c5e-4b3c-918e-b78a4f6a7885"
   },
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(2,4,figsize=(12,6))\n",
    "for row in axs:    \n",
    "    for ax in row: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9953,
     "status": "ok",
     "timestamp": 1598558697956,
     "user": {
      "displayName": "Aminul Momin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9MzmBPiSWyWQKLRRgH6rq-lvcGB6Gsr7EiF-Z3g=s64",
      "userId": "06630141247374541233"
     },
     "user_tz": 240
    },
    "hidden": true,
    "id": "Uq2pazdq4a1O",
    "outputId": "ba95e081-b802-4963-edf4-802236eb91d1"
   },
   "outputs": [],
   "source": [
    "params.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "hidden": true,
    "id": "LH3qsrbGJG-y"
   },
   "source": [
    "#### Step 7: stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training in Using Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define softmax classifier class\n",
    "\n",
    "class SoftMax(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<b style='color:red'> Click Here to see Complete Training of Softmax Net</b>\n",
    "\n",
    "<!---\n",
    "input_dim, output_dim = 28*28, 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "\n",
    "model = SoftMax(input_dim, output_dim)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trn_ds = dsets.MNIST(root='~/Data', download=False, train=True, transform=transforms.ToTensor())\n",
    "vld_ds = dsets.MNIST(root='~/Data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, batch_size=batch_size)\n",
    "vld_dl = DataLoader(vld_ds, batch_size=batch_size)\n",
    "\n",
    "epochs = 10\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in trn_dl:\n",
    "        z    = model(xb.view(-1, 28*28))\n",
    "        loss = criterion(z, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    correct = 0\n",
    "    for xb, yb in vld_dl:\n",
    "        y = model(xb.view(-1, 28*28))\n",
    "        _max, idx = torch.max(y.data, axis=1)\n",
    "        correct += (yb == idx).sum()\n",
    "    \n",
    "    losses.append(loss)\n",
    "    accuracies.append(correct/len(vld_ds))        \n",
    "        \n",
    "        \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(losses, color=color)\n",
    "ax1.set_xlabel('epoch',color=color)\n",
    "ax1.set_ylabel('total loss',color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  \n",
    "ax2.plot( accuracies, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## [torch.nn](https://pytorch.org/docs/stable/nn.html) / [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`nn.Module.parameter(...)`, `nn.Module.state_dict(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lin_mdl = nn.Linear(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(list(lin_mdl.parameters()), lin_mdl.state_dict(), sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[*lin_mdl.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Net model class\n",
    "\n",
    "class NetModuleList(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1: x = F.relu(linear_transform(x))\n",
    "            else: activation = linear_transform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_seq1 = nn.Sequential(\n",
    "          nn.Linear(2, 50),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "\n",
    "model_seq2 = nn.Sequential(OrderedDict([\n",
    "          ('lin1', nn.Linear(2,50)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('lin2', nn.Linear(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the function for training the model\n",
    "\n",
    "def train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n",
    "    LOSS = []\n",
    "    ACC = []\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            LOSS.append(loss.item())           # Loss for each batch\n",
    "        \n",
    "        ACC.append(accuracy(model, data_set))  # Accuracy for each epoch\n",
    "    \n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(LOSS, color = color)\n",
    "    ax1.set_xlabel('Iteration', color = color)\n",
    "    ax1.set_ylabel('total loss', color = color)\n",
    "    ax1.tick_params(axis = 'y', color = color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color = color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(ACC, color = color)\n",
    "    ax2.tick_params(axis = 'y', color = color)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    \n",
    "    plt.show()\n",
    "    return LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train the model with 1 hidden layer with 50 neurons\n",
    "\n",
    "Layers = [2, 50, 3]\n",
    "model = NetModuleList(Layers)\n",
    "learning_rate = 0.10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loader = DataLoader(dataset=data_set, batch_size=20)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LOSS = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n",
    "\n",
    "plot_decision_regions_3class(model, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### [torch.nn.LossFunctioons](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [`nn.NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### [`nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Activation Funcrions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-24.5198, -40.3251, -10.6257,   3.2256],\n",
       "        [ 25.0067,   6.4096,   3.9762,   5.7944],\n",
       "        [ -1.3002, -21.8870,  -2.8411,   7.4455],\n",
       "        [ 30.7034,  12.0852,   7.9834,   8.9524],\n",
       "        [ -4.8147,   1.2925,  -0.3343,  -1.8650],\n",
       "        [-11.4197, -11.3090,  -4.6375,  -1.9637]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(42);\n",
    "X = torch.randn((6,3))*10\n",
    "W = torch.randn(3, 4)\n",
    "Z = X@W\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.relu(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000,  0.9968],\n",
       "        [ 1.0000,  1.0000,  0.9993,  1.0000],\n",
       "        [-0.8618, -1.0000, -0.9932,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.9999,  0.8598, -0.3224, -0.9531],\n",
       "        [-1.0000, -1.0000, -0.9998, -0.9614]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_rlu = torch.relu(Z); acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.tanh(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000,  0.9968],\n",
       "        [ 1.0000,  1.0000,  0.9993,  1.0000],\n",
       "        [-0.8618, -1.0000, -0.9932,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.9999,  0.8598, -0.3224, -0.9531],\n",
       "        [-1.0000, -1.0000, -0.9998, -0.9614]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_th = torch.tanh(Z); acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `softmax(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return (x.exp()/(x.exp().sum(-1, keepdim=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000,  0.9968],\n",
       "        [ 1.0000,  1.0000,  0.9993,  1.0000],\n",
       "        [-0.8618, -1.0000, -0.9932,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.9999,  0.8598, -0.3224, -0.9531],\n",
       "        [-1.0000, -1.0000, -0.9998, -0.9614]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_sm = softmax(Z); acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### `torch.sigmoid(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000, -1.0000,  0.9968],\n",
       "        [ 1.0000,  1.0000,  0.9993,  1.0000],\n",
       "        [-0.8618, -1.0000, -0.9932,  1.0000],\n",
       "        [ 1.0000,  1.0000,  1.0000,  1.0000],\n",
       "        [-0.9999,  0.8598, -0.3224, -0.9531],\n",
       "        [-1.0000, -1.0000, -0.9998, -0.9614]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts_sig = torch.sigmoid(Z); acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## [torch.optim (Optimizers)](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(optim)\n",
    "# help(optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## [torch.utils.data](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### [torch.util.data.Dataset(...)](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Dataset is an abstract class\n",
    "- All datasets that represent a map from keys to data samples should subclass it. \n",
    "- All subclasses should overwrite `__getitem__()`, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite `__len__()`, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### [torch.util.data.DataLoader(...)](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "- The DataLoader supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning.\n",
    "\n",
    "```python\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None, generator=None, *, prefetch_factor=2, persistent_workers=False)\n",
    "```\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- `dataset (Dataset)` $→$ dataset from which to load the data.\n",
    "\n",
    "- `batch_size (int, optional)` $→$ how many samples per batch to load (default: 1).\n",
    "\n",
    "- `shuffle (bool, optional)` $→$ set to True to have the data reshuffled at every epoch (default: False).\n",
    "\n",
    "- `sampler (Sampler or Iterable, optional)` $→$ defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented. If specified, shuffle must not be specified.\n",
    "\n",
    "- `batch_sampler (Sampler or Iterable, optional)` $→$ like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
    "\n",
    "- `num_workers (int, optional)` $→$ how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
    "\n",
    "- `collate_fn (callable, optional)` $→$ merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\n",
    "\n",
    "- `pin_memory (bool, optional)` $→$ If True, the data loader will copy Tensors into CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.\n",
    "\n",
    "- `drop_last (bool, optional)` $→$ set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)\n",
    "\n",
    "- `timeout (numeric, optional)` $→$ if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)\n",
    "\n",
    "- `worker_init_fn (callable, optional)` $→$ If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None)\n",
    "\n",
    "- `generator (torch.Generator, optional)` $→$ If not None, this RNG will be used by RandomSampler to generate random indexes and multiprocessing to generate base_seed for workers. (default: None)\n",
    "\n",
    "- `prefetch_factor (int, optional, keyword-only arg)` $→$ Number of samples loaded in advance by each worker. 2 means there will be a total of 2 * num_workers samples prefetched across all workers. (default: 2)\n",
    "\n",
    "- `persistent_workers (bool, optional)` $→$ If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset instances alive. (default: False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Primer of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Create your Own Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define class for dataset\n",
    "class toy_set(Dataset):\n",
    "    \n",
    "    # Constructor with defult values \n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform: sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- The dataset object is an Iterable\n",
    "- The dataset object is Indexable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "our_dataset = toy_set()\n",
    "print(our_dataset)\n",
    "print(len(our_dataset))\n",
    "print(our_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Create your Own Transformers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can also create a class for transforming the data. In this case, we will try to add 1 to x and multiply y by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class add_mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, addx = 1, muly = 2):\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "    \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.addx\n",
    "        y = y * self.muly\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_m = add_mult()\n",
    "data_set = toy_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    x, y = data_set[i]\n",
    "    print(f'Index: {i}; Original x: {x}; Original y: {y}')\n",
    "    x_, y_ = a_m(data_set[i])\n",
    "    print(f'Index: {i}; Transformed x: {x_}; Transformed y: {y_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The same result is obtained using following method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cust_data_set = toy_set(transform = a_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    x, y = cust_data_set[i]\n",
    "    print(f'Index: {i}; Transformed x: {x}; Transformed y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Compose Several Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can compose multiple transforms on the dataset object. First, import <code>transforms</code> from <code>torchvision</code>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The new <code>Compose</code> object will perform each transform concurrently as shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.3.1_trasform.png\" width=\"500\" alt=\"Compose PyTorch\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combine the add_mult() and mult()\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "print(\"The combination of transforms (Compose): \", data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_transform(data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = data_set[0]\n",
    "x_,y_= data_transform(data_set[0])\n",
    "print( 'Original x: ', x, 'Original y: ', y)\n",
    "\n",
    "print( 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a new toy_set object with compose object as transform\n",
    "compose_data_set = toy_set(transform = data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us see what happened on index 0:\n",
    "- The original value of <code>x</code> is <i>[2, 2]</i>, and the original value of <code>y</code> is [1].\n",
    "- If we only applied <code>add_mult()</code> on the original dataset:\n",
    "    - the <code>x</code> became <i>[3, 3]</i> and y became <i>[2]</i>. \n",
    "    \n",
    "- Now apply both <code>add_mult()</code> and <code>mult()</code>: \n",
    "    - The result of x is <i>[300, 300]</i> and y is <i>[200]</i>. \n",
    "    - The calculation which is equavalent to the compose is <i> x = ([2, 2] + 1) x 100 = [300, 300], y = ([1] x 2) x 100 = 200</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Try to combine the <code>mult()</code> and <code>add_mult()</code> as <code>mult()</code> to be executed first. And apply this on a new <code>toy_set</code> dataset. Print out the first 3 elements in the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  [torchvision](https://pytorch.org/vision/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = torch.tensor([[1, 0], [0, 1]])\n",
    "Y = torch.tensor([[2, 1], [1, 2]]) \n",
    "X_times_Y = X * Y; X_times_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### [torchvision.datasets(...)](https://pytorch.org/vision/stable/datasets.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- All datasets are subclasses of `torch.utils.data.Dataset`, they have `__getitem__` and `__len__` methods implemented. Hence, they can all be passed to a `torch.utils.data.DataLoader` which can load multiple samples in parallel using `torch.multiprocessing` workers. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(tfms.ToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import the prebuilt dataset into variable dataset\n",
    "dataset = dsets.MNIST(\n",
    "    root = '~/Data/', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = tfms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Examine whether the elements in dataset MNIST are tuples, and what is in the tuple?\n",
    "\n",
    "print(\"Type of the first element: \", type(dataset[0]))\n",
    "print(\"The length of the tuple: \", len(dataset[0]))\n",
    "print(\"The shape of the first element in the tuple: \", dataset[0][0].shape)\n",
    "print(\"The type of the first element in the tuple\", type(dataset[0][0]))\n",
    "print(\"The second element in the tuple: \", dataset[0][1])\n",
    "print(\"The type of the second element in the tuple: \", type(dataset[0][1]))\n",
    "print(\"As the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the first element in the dataset\n",
    "show_data(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the second element in the dataset\n",
    "show_data(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Combine two transforms: crop and convert to tensor. Apply the compose to MNIST dataset\n",
    "\n",
    "croptensor_data_transform = tfms.Compose([tfms.CenterCrop(20), tfms.ToTensor()])\n",
    "dataset = dsets.MNIST(\n",
    "    root = '~/Data/', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = croptensor_data_transform\n",
    ")\n",
    "\n",
    "print(\"The shape of the first element in the first tuple: \", dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the first element in the dataset\n",
    "show_data(dataset[0], shape = (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the second element in the dataset\n",
    "show_data(dataset[1],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Construct the compose. Apply it on MNIST dataset. Plot the image out.\n",
    "\n",
    "fliptensor_data_transform = tfms.Compose([tfms.RandomHorizontalFlip(p = 1),tfms.ToTensor()])\n",
    "\n",
    "dataset = dsets.MNIST(\n",
    "    root = '~/Data/', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = fliptensor_data_transform\n",
    ")\n",
    "\n",
    "show_data(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### [Pretrained Torchvision Models](https://pytorch.org/vision/stable/models.html#):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## End to End Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as tfms\n",
    "import torchvision.models as mdls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = '/Users/a.momin/Data/bird_species/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
