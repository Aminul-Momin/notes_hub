{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a5099a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#End-to-End-Deep-Learning-with-PyTorch:\" data-toc-modified-id=\"End-to-End-Deep-Learning-with-PyTorch:-1\">End to End Deep Learning with PyTorch:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Transform-data\" data-toc-modified-id=\"Transform-data-1.0.1\">Transform data</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-1.0.2\">Load data</a></span></li><li><span><a href=\"#Data-Loaders\" data-toc-modified-id=\"Data-Loaders-1.0.3\">Data Loaders</a></span></li><li><span><a href=\"#Make-iterator-of-data\" data-toc-modified-id=\"Make-iterator-of-data-1.0.4\">Make iterator of data</a></span></li><li><span><a href=\"#Altogether\" data-toc-modified-id=\"Altogether-1.0.5\">Altogether</a></span></li></ul></li><li><span><a href=\"#5.3.-Define-layers-and-operations\" data-toc-modified-id=\"5.3.-Define-layers-and-operations-1.1\">5.3. Define layers and operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-a-Neural-Network-class-with-defined-layers\" data-toc-modified-id=\"Build-a-Neural-Network-class-with-defined-layers-1.1.1\">Build a Neural Network class with defined layers</a></span></li><li><span><a href=\"#Build-a-Neural-Network-class-with-arbitrary-layers\" data-toc-modified-id=\"Build-a-Neural-Network-class-with-arbitrary-layers-1.1.2\">Build a Neural Network class with arbitrary layers</a></span></li><li><span><a href=\"#Use-the-sequential-method-with-defined-layers\" data-toc-modified-id=\"Use-the-sequential-method-with-defined-layers-1.1.3\">Use the sequential method with defined layers</a></span></li><li><span><a href=\"#Use-the-sequential-method-with-defined-layers-by-OrderedDict\" data-toc-modified-id=\"Use-the-sequential-method-with-defined-layers-by-OrderedDict-1.1.4\">Use the sequential method with defined layers by <code>OrderedDict</code></a></span></li></ul></li><li><span><a href=\"#5.4.-Define-criterion,-optimizer,-and-validation\" data-toc-modified-id=\"5.4.-Define-criterion,-optimizer,-and-validation-1.2\">5.4. Define criterion, optimizer, and validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-loss-function-criterion-and-optimizer\" data-toc-modified-id=\"Define-loss-function-criterion-and-optimizer-1.2.1\">Define loss function criterion and optimizer</a></span></li><li><span><a href=\"#Define-a-validation-function\" data-toc-modified-id=\"Define-a-validation-function-1.2.2\">Define a validation function</a></span></li></ul></li><li><span><a href=\"#5.5.-Train-a-neural-network\" data-toc-modified-id=\"5.5.-Train-a-neural-network-1.3\">5.5. Train a neural network</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialize-weights-and-biases\" data-toc-modified-id=\"Initialize-weights-and-biases-1.3.1\">Initialize weights and biases</a></span></li><li><span><a href=\"#An-example-forward-pass\" data-toc-modified-id=\"An-example-forward-pass-1.3.2\">An example forward pass</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.3.3\">Train</a></span></li><li><span><a href=\"#Train-and-validation\" data-toc-modified-id=\"Train-and-validation-1.3.4\">Train and validation</a></span></li></ul></li><li><span><a href=\"#5.6.-Inference\" data-toc-modified-id=\"5.6.-Inference-1.4\">5.6. Inference</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-predictions\" data-toc-modified-id=\"Check-predictions-1.4.1\">Check predictions</a></span></li></ul></li><li><span><a href=\"#5.7.-Save-and-load-trained-networks\" data-toc-modified-id=\"5.7.-Save-and-load-trained-networks-1.5\">5.7. Save and load trained networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-a-dictionary,-save-to-file-checkpoint.pth\" data-toc-modified-id=\"Build-a-dictionary,-save-to-file-checkpoint.pth-1.5.1\">Build a dictionary, save to file <code>checkpoint.pth</code></a></span></li><li><span><a href=\"#Load-checkpoints\" data-toc-modified-id=\"Load-checkpoints-1.5.2\">Load checkpoints</a></span></li></ul></li><li><span><a href=\"#5.8.-Transfer-learning-with-CUDA\" data-toc-modified-id=\"5.8.-Transfer-learning-with-CUDA-1.6\">5.8. Transfer learning with CUDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initialize-data\" data-toc-modified-id=\"Initialize-data-1.6.1\">Initialize data</a></span></li><li><span><a href=\"#Load-in-a-pre-trained-model-such-as-DenseNet\" data-toc-modified-id=\"Load-in-a-pre-trained-model-such-as-DenseNet-1.6.2\">Load in a pre-trained model such as <a href=\"http://pytorch.org/docs/0.3.0/torchvision/models.html#id5\" rel=\"nofollow\" target=\"_blank\">DenseNet</a></a></span></li><li><span><a href=\"#Use-GPU-for-really-deep-neural-network\" data-toc-modified-id=\"Use-GPU-for-really-deep-neural-network-1.6.3\">Use GPU for really deep neural network</a></span><ul class=\"toc-item\"><li><span><a href=\"#Accurcy-on-the-test-set\" data-toc-modified-id=\"Accurcy-on-the-test-set-1.6.3.1\">Accurcy on the test set</a></span></li><li><span><a href=\"#Keep-GPU-server-awake\" data-toc-modified-id=\"Keep-GPU-server-awake-1.6.3.2\">Keep GPU server awake</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b94863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "# import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627745d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69cff80",
   "metadata": {},
   "source": [
    "## End to End Deep Learning with PyTorch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b2a74",
   "metadata": {},
   "source": [
    "[PyTorch](https://pytorch.org/) is a framework for building and training neural networks\n",
    "\n",
    "- Behaves like numpy\n",
    "- Moves tensors (a generalization of matrices) to GPUs for faster processing\n",
    "- Automatically calculates gradients (for backpropagation) and another module specifically for building neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f2eb1",
   "metadata": {},
   "source": [
    " \n",
    "- #### Transform data\n",
    "\n",
    "  More transforms available from [documentation](http://pytorch.org/docs/master/torchvision/transforms.html)\n",
    "\n",
    "  - During training, can randomly rotate, mirror, scale, and/or crop images.\n",
    "  - During testing, use images that aren't altered (except need to normalize, resize, or crop the same way).\n",
    "  - Normalizing helps keep the weights near zero which in turn makes backpropagation more stable. Subtract by means; divide by standard deviations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70572d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                            # transforms.Resize(255),\n",
    "                            # transforms.CenterCrop(224),\n",
    "                            transforms.RandomRotation(30),\n",
    "                            transforms.RandomResizedCrop(100),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                [0.5, 0.5, 0.5])])\n",
    "test_transforms = transforms.Compose([\n",
    "                            transforms.RandomResizedCrop(100),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12720c",
   "metadata": {},
   "source": [
    "- #### Load data\n",
    "\n",
    "  The easiest way to load image data is with `datasets.ImageFolder` from `torchvision` ([documentation](http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fabb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "  train_data = datasets.ImageFolder('path/to/root_train', transform=train_transforms)\n",
    "  test_data = datasets.ImageFolder('path/to/root_test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aebe48",
   "metadata": {},
   "source": [
    "ImageFolder expects the files and directories to be constructed like root/dog/xxx.png, root/cat/123.png."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511566d",
   "metadata": {},
   "source": [
    "- #### Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809de41a",
   "metadata": {},
   "source": [
    "  The `DataLoader` takes a dataset (such as from `ImageFolder`) and returns batches of images and the corresponding labels. Here `dataloader` is a [generator](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/). To get data out of it, need to loop through it or convert it to an iterator and call `next()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "  testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ebe94",
   "metadata": {},
   "source": [
    "- #### Make iterator of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Looping through it, get a batch on each loop\n",
    "  for images, labels in trainloader:\n",
    "      pass\n",
    "\n",
    "  # Get one batch\n",
    "  images, labels = next(iter(trainloader))\n",
    "\n",
    "  # Visualize\n",
    "  fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "  for ii in range(4):\n",
    "      ax = axes[ii]\n",
    "      helper.imshow(images[ii], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824196d",
   "metadata": {},
   "source": [
    "- #### Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Make iterator of data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# images is a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images.\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5fe4b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.3. Define layers and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c776b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, use the raw output, called the **logits**, to calculate the loss. Alternatively, use the **log-softmax**, which is a log probability that comes with a [lot of benefits](https://en.wikipedia.org/wiki/Log_probability) (e.g. faster and more accurate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a60d4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Build a Neural Network class with defined layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53134193",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Defining the layers, 128, 64, 10 units each\n",
    "        self.fc1 = nn.Linear(784, 128) # fully connected (fc) layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2944fb3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Build a Neural Network class with arbitrary layers\n",
    "\n",
    "  `nn.ModuleList` works similar as a normal Python list, except that it registers each hidden layer Linear module properly so the model is aware of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3959127",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            drop_p: float between 0 and 1, dropout probability\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # Add the first layer, input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "\n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "\n",
    "        # Add the output layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "        # Include dropout\n",
    "        self.dropout = nn.Dropout(p=drop_p) # Has to be turned off during inference\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "\n",
    "        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3afcf5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Use the sequential method with defined layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35671c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      # nn.Softmax(dim=1)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8f6fa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Use the sequential method with defined layers by `OrderedDict`\n",
    "\n",
    "  Each operation must have a different name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eba583",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('logits', nn.Linear(hidden_sizes[1], output_size)),\n",
    "    # ('softmax', nn.Softmax(dim=1))\n",
    "]))\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a45d2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.4. Define criterion, optimizer, and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b994f0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Define loss function criterion and optimizer\n",
    "\n",
    "  [Criterion](https://pytorch.org/docs/master/nn.html#loss-functions)\n",
    "  \n",
    "  - `nn.CrossEntropyLoss` for `logits` output\n",
    "  - `nn.NLLLoss()` ([negative log loss](http://pytorch.org/docs/master/nn.html#nllloss)) for `log-softmax` output\n",
    "\n",
    "  [Optimizer](https://pytorch.org/docs/master/optim.html)\n",
    "  \n",
    "  - `optim.SGD`\n",
    "  - `optim.Adam`, a variant of stochastic gradient descent which includes momentum and in general trains faster than basic SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6de25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Network(784, 10, [516, 256], drop_p=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effcd27",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Define a validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302bbda",
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Measure the validation loss and accuracy\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output) # get the class probabilities from log-softmax\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ebc97",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.5. Train a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a3e4f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. Set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac987139",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Initialize weights and biases\n",
    "\n",
    "  - Automatic initialization\n",
    "\n",
    "    ```python\n",
    "    print(model.fc1.weight)\n",
    "    print(model.fc1.bias)\n",
    "    ```\n",
    "\n",
    "  - Custom initialization\n",
    "\n",
    "    ```python\n",
    "    # Set biases to all zeros\n",
    "    model.fc1.bias.data.fill_(0)\n",
    "\n",
    "    # sample from random normal with standard dev = 0.01\n",
    "    model.fc1.weight.data.normal_(std=0.01)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a846e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### An example forward pass\n",
    "\n",
    "  ```python\n",
    "  # Grab some data\n",
    "  dataiter = iter(trainloader)\n",
    "  images, labels = dataiter.next()\n",
    "\n",
    "  # Resize images into a 1D vector, new shape is (batch size, color channels, image pixels)\n",
    "  images.resize_(64, 1, 784)\n",
    "  # or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "  # Forward pass through the network\n",
    "  img_idx = 0\n",
    "  ps = model.forward(images[img_idx,:])\n",
    "\n",
    "  img = images[img_idx]\n",
    "  helper.view_classify(img.view(1, 28, 28), ps)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cced5d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Train\n",
    "\n",
    "  ```python\n",
    "  epochs = 3\n",
    "  print_every = 40\n",
    "  steps = 0\n",
    "\n",
    "  for e in range(epochs):\n",
    "      running_loss = 0\n",
    "      for images, labels in iter(trainloader):\n",
    "          steps += 1\n",
    "\n",
    "          # Flatten MNIST images into a 784 long vector\n",
    "          images.resize_(images.size()[0], 784)\n",
    "\n",
    "          # Clear the gradients, do this because gradients are accumulated\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Forward pass to get the output\n",
    "          output = model.forward(images)\n",
    "\n",
    "          # Use output to calculate loss\n",
    "          loss = criterion(output, labels)\n",
    "\n",
    "          # Backward pass to calculate the gradients\n",
    "          loss.backward()\n",
    "\n",
    "          # Update weights\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          if steps % print_every == 0:\n",
    "              print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                    \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "              # print('Updated weights - ', model.fc1.weight)\n",
    "\n",
    "              running_loss = 0\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43044c7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96e83d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "print_every = 40\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Dropout is turned on for training\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            # Make sure network is in eval mode for inference\n",
    "            model.eval()\n",
    "\n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "\n",
    "            running_loss = 0\n",
    "\n",
    "            # Make sure training is back on\n",
    "            model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae417f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4ef3c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bd7aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "img = img.view(1, 784) # Convert 2D image to 1D vector\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "# If output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(output, dim=1)\n",
    "\n",
    "# If output are log-softmax, need to take exponential for probabilities\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda59da",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.7. Save and load trained networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb6944",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Need to save both model architecture and network parameters (`state_dict`)\n",
    "\n",
    "- #### Build a dictionary, save to file `checkpoint.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e428878",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "            'output_size': 10,\n",
    "            'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "            'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c582dd4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645600d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                            checkpoint['output_size'],\n",
    "                            checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e129f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5.8. Transfer learning with CUDA\n",
    "\n",
    "Transfer learning: use a pre-trained network on images not in the training set.\n",
    "\n",
    "Pre-trained networks, e.g. networks trained on [ImageNet](http://www.image-net.org/) (available from [`torchvision.models`](http://pytorch.org/docs/0.3.0/torchvision/models.html)), can be used to solved challenging problems in computer vision. ImageNet, a massive dataset with >1 million labeled images in 1000 categories, is used to train deep neural networks using an architecture called convolutional layers. These trained models work astonishingly well as feature detectors for images they weren't trained on. Learn more about convolutional neural networks [here](cnn.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbe1a8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Initialize data\n",
    "\n",
    "  - Most of the pretrained models require the input to be 224x224 images.\n",
    "  - Match the normalization used when the models were trained: for the color channels, the means are [0.485, 0.456, 0.406] and the standard deviations are [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446db24",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ec0dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8996d0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Load in a pre-trained model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4def6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005c6ab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "  This model is built out of two main parts\n",
    "  - Features: a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The features will work perfectly on their own.\n",
    "  - Classifier: a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for other specific problem. Need to replace the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ce9e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)), # 1024 must match\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8d863",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- #### Use GPU for really deep neural network\n",
    "\n",
    "  Deep learning frameworks often use [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch:\n",
    "\n",
    "  - Move model parameters and other tensors to the GPU memory: `model.to('cuda')`.\n",
    "  - Move back from the GPU: `model.to('cpu')`, which should commonly be set when need to operate on the network output outside of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f8fa4a",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7817eb12f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# At beginning of the script, write device agnostic which will automatically use CUDA if it's enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Only train the classifier parameters, feature parameters are frozen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# At beginning of the script, write device agnostic which will automatically use CUDA if it's enabled\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001) # Only train the classifier parameters, feature parameters are frozen\n",
    "\n",
    "# Whenever you get a new Tensor or Module, this won't copy if they are already on the desired device\n",
    "model.to(device)\n",
    "\n",
    "epochs = 4\n",
    "print_every = 40\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for images, labels in iter(trainloader):\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device) # Move input and label tensors to the GPU\n",
    "\n",
    "        steps += 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # get the class probabilities from log-softmax\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        train_accuracy += equality.type(torch.FloatTensor).mean()\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/print_every))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3915b3b4",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - ##### Accurcy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142a2ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47278a71",
   "metadata": {
    "hidden": true
   },
   "source": [
    " - ##### Keep GPU server awake\n",
    "\n",
    "  [workspace_utils.py](Code/deep_learning/workspace_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb33c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from workspace_utils import keep_awake\n",
    "\n",
    "for i in keep_awake(range(5)):  # anything that happens inside this loop will keep the workspace active\n",
    "  # do iteration with lots of work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958afe6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from workspace_utils import active_session\n",
    "\n",
    "with active_session():\n",
    "  # do long-running work here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a3c3c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
