{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704d38fd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Clustering:-grouping-observations-together\" data-toc-modified-id=\"Clustering:-grouping-observations-together-1\">Clustering: grouping observations together</a></span><ul class=\"toc-item\"><li><span><a href=\"#K-means-clustering\" data-toc-modified-id=\"K-means-clustering-1.1\">K-means clustering</a></span></li><li><span><a href=\"#Hierarchical-agglomerative-clustering:-Ward\" data-toc-modified-id=\"Hierarchical-agglomerative-clustering:-Ward-1.2\">Hierarchical agglomerative clustering: Ward</a></span></li></ul></li><li><span><a href=\"#Component-Analysis\" data-toc-modified-id=\"Component-Analysis-2\">Component Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Principal-component-analysis:-PCA\" data-toc-modified-id=\"Principal-component-analysis:-PCA-2.1\">Principal component analysis: PCA</a></span></li><li><span><a href=\"#Independent-Component-Analysis:-ICA\" data-toc-modified-id=\"Independent-Component-Analysis:-ICA-2.2\">Independent Component Analysis: ICA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6162bdb",
   "metadata": {},
   "source": [
    "<h1>Seeking Representations of the Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bdb23",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clustering: grouping observations together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636980b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Given the iris dataset, if we knew that there were 3 types of iris, but\n",
    "did not have access to a taxonomist to label them: we could try a\n",
    "**clustering task**: split the observations into well-separated group\n",
    "called *clusters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe8a6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "   # Set the PRNG\n",
    "   import numpy as np\n",
    "   np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb372d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45324f7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that there exist a lot of different clustering criteria and associated\n",
    "algorithms. The simplest clustering algorithm is :ref:`k_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875c4b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "X_iris, y_iris = datasets.load_iris(return_X_y=True)\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris)\n",
    "print(k_means.labels_[::10])\n",
    "print(y_iris[::10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf9b09",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is absolutely no guarantee of recovering a ground truth. First,\n",
    "choosing the right number of clusters is hard. Second, the algorithm\n",
    "is sensitive to initialization, and can fall into local minima,\n",
    "although scikit-learn employs several tricks to mitigate this issue.\n",
    "\n",
    "\n",
    "\n",
    "- **Application example: vector quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f004e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Clustering in general and KMeans, in particular, can be seen as a way\n",
    "of choosing a small number of exemplars to compress the information.\n",
    "The problem is sometimes known as\n",
    "[vector quantization](<https://en.wikipedia.org/wiki/Vector_quantization>)\n",
    "For instance, this can be used to posterize an image::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4d99d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "try:\n",
    "    face = sp.face(gray=True)\n",
    "except AttributeError:\n",
    "    from scipy import misc\n",
    "    face = misc.face(gray=True)\n",
    "X = face.reshape((-1, 1)) # We need an (n_sample, n_feature) array\n",
    "k_means = cluster.KMeans(n_clusters=5, n_init=1)\n",
    "k_means.fit(X)\n",
    "values = k_means.cluster_centers_.squeeze()\n",
    "labels = k_means.labels_\n",
    "face_compressed = np.choose(labels, values)\n",
    "face_compressed.shape = face.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d051e3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Hierarchical agglomerative clustering: Ward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865d1de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A`hierarchical_clustering` method is a type of cluster analysis\n",
    "that aims to build a hierarchy of clusters. In general, the various approaches\n",
    "of this technique are either:\n",
    "\n",
    "  * **Agglomerative** - bottom-up approaches: each observation starts in its\n",
    "    own cluster, and clusters are iteratively merged in such a way to\n",
    "    minimize a *linkage* criterion. This approach is particularly interesting\n",
    "    when the clusters of interest are made of only a few observations. When\n",
    "    the number of clusters is large, it is much more computationally efficient\n",
    "    than k-means.\n",
    "\n",
    "  * **Divisive** - top-down approaches: all observations start in one\n",
    "    cluster, which is iteratively split as one moves down the hierarchy.\n",
    "    For estimating large numbers of clusters, this approach is both slow (due\n",
    "    to all observations starting as one cluster, which it splits recursively)\n",
    "    and statistically ill-posed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ecfab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Connectivity-constrained clustering**\n",
    "\n",
    "With agglomerative clustering, it is possible to specify which samples can be\n",
    "clustered together by giving a connectivity graph. Graphs in scikit-learn\n",
    "are represented by their adjacency matrix. Often, a sparse matrix is used.\n",
    "This can be useful, for instance, to retrieve connected regions (sometimes\n",
    "also referred to as connected components) when clustering an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29254cfa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage.data import coins\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.transform import rescale\n",
    "rescaled_coins = rescale(gaussian_filter(coins(), sigma=2), 0.2, mode='reflect', anti_aliasing=False, multichannel=False)\n",
    "X = np.reshape(rescaled_coins, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522568c3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need a vectorized version of the image. `'rescaled_coins'` is a down-scaled\n",
    "version of the coins image to speed up the process::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d62ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import grid_to_graph\n",
    "connectivity = grid_to_graph(*rescaled_coins.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481a857",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define the graph structure of the data. Pixels connected to their neighbors::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0caa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 27  # number of regions\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward', connectivity=connectivity)\n",
    "ward.fit(X)\n",
    "label = np.reshape(ward.labels_, rescaled_coins.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32e967",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Feature agglomeration**\n",
    "\n",
    "We have seen that sparsity could be used to mitigate the curse of\n",
    "dimensionality, *i.e* an insufficient amount of observations compared to the\n",
    "number of features. Another approach is to merge together similar\n",
    "features: **feature agglomeration**. This approach can be implemented by\n",
    "clustering in the feature direction, in other words clustering the\n",
    "transposed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d75422",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "images = digits.images\n",
    "X = np.reshape(images, (len(images), -1))\n",
    "connectivity = grid_to_graph(*images[0].shape)\n",
    "agglo = cluster.FeatureAgglomeration(connectivity=connectivity, n_clusters=32)\n",
    "agglo.fit(X)\n",
    "X_reduced = agglo.transform(X)\n",
    "X_approx = agglo.inverse_transform(X_reduced)\n",
    "images_approx = np.reshape(X_approx, images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4b7b9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- ``transform`` and ``inverse_transform`` methods\n",
    "\n",
    "   Some estimators expose a ``transform`` method, for instance to reduce\n",
    "   the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f927ec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ada03b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Decompos a signal into components and loadings\n",
    "    - If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that *X = L C*. Different criteria exist to choose the components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11796827",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Principal component analysis: PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2f781",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`PCA` selects the successive components that explain the maximum variance in the signal.\n",
    "\n",
    "\n",
    "The point cloud spanned by the observations above is very flat in one\n",
    "direction: one of the three univariate features can almost be exactly\n",
    "computed using the other two. PCA finds the directions in which the data is\n",
    "not *flat*\n",
    "\n",
    "When used to *transform* data, PCA can reduce the dimensionality of the\n",
    "data by projecting on a principal subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121c624",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create a signal with only 2 useful dimensions\n",
    "x1 = np.random.normal(size=100)\n",
    "x2 = np.random.normal(size=100)\n",
    "x3 = x1 + x2\n",
    "X = np.c_[x1, x2, x3]\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_)  # doctest: +SKIP\n",
    "# As we can see, only the 2 first components are useful\n",
    "pca.n_components = 2\n",
    "X_reduced = pca.fit_transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668b393",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Independent Component Analysis: ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8c795",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`ICA` selects components so that the distribution of their loadings carries\n",
    "a maximum amount of independent information. It is able to recover\n",
    "**non-Gaussian** independent signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abe59b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate sample data\n",
    "time = np.linspace(0, 10, 2000)\n",
    "s1 = np.sin(2 * time)  # Signal 1 : sinusoidal signal\n",
    "s2 = np.sign(np.sin(3 * time))  # Signal 2 : square signal\n",
    "s3 = signal.sawtooth(2 * np.pi * time)  # Signal 3: saw tooth signal\n",
    "S = np.c_[s1, s2, s3]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "S /= S.std(axis=0)  # Standardize data\n",
    "\n",
    "# Mix data\n",
    "A = np.array([[1, 1, 1], [0.5, 2, 1], [1.5, 1, 2]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Generate observations\n",
    "\n",
    "# Compute ICA\n",
    "ica = decomposition.FastICA()\n",
    "S_ = ica.fit_transform(X)  # Get the estimated sources\n",
    "A_ = ica.mixing_.T\n",
    "np.allclose(X,  np.dot(S_, A_) + ica.mean_)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
