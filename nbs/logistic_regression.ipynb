{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755465a9",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1\">Logistic Regression</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#FIRST-way-to-formulate-the-Logistic-Regression:\" data-toc-modified-id=\"FIRST-way-to-formulate-the-Logistic-Regression:-1.0.0.1\">FIRST way to formulate the Logistic Regression:</a></span></li><li><span><a href=\"#SECOND-way-to-formulate-the-Logistic-Regression:\" data-toc-modified-id=\"SECOND-way-to-formulate-the-Logistic-Regression:-1.0.0.2\">SECOND way to formulate the Logistic Regression:</a></span></li><li><span><a href=\"#Mathematical-Equations:\" data-toc-modified-id=\"Mathematical-Equations:-1.0.0.3\">Mathematical Equations:</a></span></li><li><span><a href=\"#API-(sklearn.linear_model.LogisticRegression):\" data-toc-modified-id=\"API-(sklearn.linear_model.LogisticRegression):-1.0.0.4\">API (sklearn.linear_model.LogisticRegression):</a></span></li><li><span><a href=\"#Dataset:\" data-toc-modified-id=\"Dataset:-1.0.0.5\">Dataset:</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.0.0.6\">Model</a></span></li><li><span><a href=\"#Evaluations:\" data-toc-modified-id=\"Evaluations:-1.0.0.7\">Evaluations:</a></span></li><li><span><a href=\"#Multi-class-Logistic-Regressio-(Softmax)\" data-toc-modified-id=\"Multi-class-Logistic-Regressio-(Softmax)-1.0.0.8\">Multi-class Logistic Regressio (Softmax)</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Interview-Questions\" data-toc-modified-id=\"Interview-Questions-2\">Interview Questions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5120a92",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dce49e",
   "metadata": {},
   "source": [
    "##### FIRST way to formulate the Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa95794",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    J(\\boldsymbol{\\theta})\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[ y^{(i)} log\\left( \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right) + (1 - y^{(i)}) log\\left(1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right)\\right]}\\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[ y^{(i)} log\\left( (1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})^{-1} \\right) + (1 - y^{(i)}) log\\left(1 - (1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})^{-1} \\right)\\right]}\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5214db9b",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "    \\frac{J}{d \\mathbf{\\boldsymbol{\\theta}}} (\\boldsymbol{\\theta})\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "         \\frac{- y^{(i)} {(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})^{-2}(e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})(-\\mathbf{x^{(i)}})}} {\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "         + \\frac{(1 - y^{(i)})(-)(-) {(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})^{-2}(e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})(-\\mathbf{x^{(i)}}) }} {1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "         \\right]} \\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "            \\frac{y^{(i)}} {\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "            - \\frac{(1 - y^{(i)}) } {1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "        \\right]} \\cdot {(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}})^{-2}{e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} } \\cdot {\\mathbf{x^{(i)}}} \\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "            \\frac{y^{(i)}} {\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "            - \\frac{(1 - y^{(i)}) } {1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} }\n",
    "        \\right]} \\cdot \\frac{1}{\\left(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\right)} \\cdot {\\frac{e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}{ \\left(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\right)} } \\cdot {\\mathbf{x^{(i)}}} \\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "            \\frac{y^{(i)}} {\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}}\n",
    "            - \\frac{(1 - y^{(i)}) } {1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} }\n",
    "        \\right]} \\cdot \\frac{1}{\\left(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\right)} \\cdot {\\left( 1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right)} \\cdot {\\mathbf{x^{(i)}}} \\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "            \\frac{y^{(i)} - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}} { \\left( \\frac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right) \\cdot {\\left( 1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right)}}\n",
    "        \\right]} \\cdot \\frac{1}{\\left(1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\right)} \\cdot {\\left( 1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right)} \\cdot {\\mathbf{x^{(i)}}} \\\\\n",
    "    & = -\\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "        y^{(i)} - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}\n",
    "        \\right]} \\cdot {\\mathbf{x^{(i)}}} \\\\\n",
    "    & = \\dfrac{1}{m} \\sum_{i=1}^{m}{\\left[\n",
    "            \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} - y^{(i)}\n",
    "            \\right]} \\cdot {\\mathbf{x^{(i)}}}\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1e439",
   "metadata": {},
   "source": [
    "##### SECOND way to formulate the Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a37b1",
   "metadata": {},
   "source": [
    "- Loss of a Single Observation:\n",
    "\n",
    "\\begin{split}\n",
    "P \\left( y^{(i)} | x^{(i)} \\right) =\n",
    "\\begin{cases}\n",
    "  \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} & \\text{if} \\quad y^{(i)} = 1 \\\\\n",
    "  1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} = \\dfrac{1}{1 + e^{\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} & \\text{if} \\quad y^{(i)} = -1\n",
    "\\end{cases}\n",
    "\\end{split}\n",
    "\n",
    "- Combinining these two equations into one:\n",
    "\n",
    "\\begin{equation}\n",
    "  P \\left( y^{(i)} | x^{(i)} \\right) \n",
    "  = \\dfrac{1}{1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}; \\quad y^{(i)} \\in \\{1, -1\\}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "- Loss of All Observations (Total Loss):\n",
    "    - We have to take the product of indivudale probability to have one total loss function and maximize it. Therefore,\n",
    "\n",
    "\\begin{equation}  \\label{eq:1}\n",
    "\\begin{split}\n",
    "  \\mathcal{L}(\\theta) \n",
    "  &= \\prod_{i=1}^{m} P \\left( y^{(i)} | x^{(i)} \\right) \n",
    "  = \\prod_{i=1}^m \\dfrac{1}{1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}; \\quad y^{(i)} \\in \\{1, -1\\} \\\\\n",
    "  &= log\\left( \\prod_{i=1}^m \\dfrac{1}{1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right) \\\\\n",
    "  &= \\sum_{i=1}^m log\\left( \\dfrac{1}{1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right) \\\\\n",
    "  &= \\sum_{i=1}^m log\\left( 1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\right)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Now taking gradient of equation \\ref{eq:1}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "  \\nabla\\mathcal{L}(\\boldsymbol{\\theta})\n",
    "  &= -\\sum_{i=1}^m \\frac{y^{(i)} x^{(i)}}{1 + e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\cdot e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} \\cdot \\frac{e^{y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}{e^{y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\\\\n",
    "  &= -\\sum_{i=1}^m \\frac{y^{(i)} x^{(i)}}{e^{- y^{(i)} \\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}} + 1} \\\\\n",
    "  &=  -\\sum_{i=1}^m P \\left( -y^{(i)} | x^{(i)} \\right)  \\cdot y^{(i)}  x^{(i)}\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e965dd8",
   "metadata": {},
   "source": [
    "##### Mathematical Equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a77005",
   "metadata": {},
   "source": [
    "The following objective is used implementing Logistic Regression in sklearn.\n",
    "$$\n",
    "\\large \\min_{w, c} \\frac{1}{2}w^T w + C \\sum_{i=1}^n \\log\\left(e^{- y^{(i)} ({x^{(i)}}^T w + b)) + 1} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecad1fa",
   "metadata": {},
   "source": [
    "**Equation 4-13: Logistic Regression model estimated probability (vectorized form)**\n",
    "\n",
    "$\n",
    "\\hat{p} \n",
    "= h_{\\boldsymbol{\\theta}}(\\mathbf{x}) \n",
    "= \\sigma(\\boldsymbol{\\theta}^T \\mathbf{x})\n",
    "= \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9272d81",
   "metadata": {},
   "source": [
    "**Equation 4-14: Logistic function**\n",
    "\n",
    "$\n",
    "\\sigma(\\boldsymbol{\\theta}^T \\mathbf{x}) = \\dfrac{1}{1 + \\exp(-\\boldsymbol{\\theta}^T \\mathbf{x})} = \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b8eed",
   "metadata": {},
   "source": [
    "**Equation 4-15: Logistic Regression binary model prediction**\n",
    "\n",
    "$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "  0 & \\text{if } \\hat{p} < 0.5, \\\\\n",
    "  1 & \\text{if } \\hat{p} \\geq 0.5.\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b7c57",
   "metadata": {},
   "source": [
    "**Equation 4-16: Cost function of a single training instance**\n",
    "\n",
    "\\begin{split}\n",
    "    \\mathbf{\\text{Cost}}(\\boldsymbol{\\theta}) \n",
    "    &= y^{(i)} log\\left(\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}\\right) + (1 - y^{(i)}) log\\left(1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}\\right) \\\\\n",
    "   &= \\begin{cases}\n",
    "        -\\log(\\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}) & \\text{if } y = 1, \\\\\n",
    "        -\\log(1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}}) & \\text{if } y = 0.\n",
    "    \\end{cases}\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b102b12",
   "metadata": {},
   "source": [
    "**Equation 4-17: Logistic Regression cost function (`log loss` a.k.a. `Binary Cross Entropy`)**\n",
    "\n",
    "$\n",
    "J(\\boldsymbol{\\theta}) \n",
    "= -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left( \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right) + (1 - y^{(i)}) log\\left(1 - \\dfrac{1}{1 + e^{-\\boldsymbol{\\theta}^T \\mathbf{x^{(i)}}}} \\right)\\right]}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b87c5",
   "metadata": {},
   "source": [
    "**Equation 4-18: Logistic cost function partial derivatives**\n",
    "\n",
    "$\n",
    "\\dfrac{\\partial}{\\partial \\theta_j} \\text{J}(\\boldsymbol{\\theta}) = \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\left(\\mathbf{\\sigma(\\boldsymbol{\\theta}}^T \\mathbf{x}^{(i)}) - y^{(i)}\\right)\\, x_j^{(i)}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ef999f",
   "metadata": {},
   "source": [
    "**Equation 4-19: Softmax score for class k**\n",
    "\n",
    "$\n",
    "s_k(\\mathbf{x}) = ({\\boldsymbol{\\theta}^{(k)}})^T \\mathbf{x}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe53819",
   "metadata": {},
   "source": [
    "**Equation 4-20: Softmax function**\n",
    "\n",
    "$\n",
    "\\hat{p}_k = \\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}\n",
    "$ =\n",
    "$  \\Large \\frac{e^{\\theta \\cdot x^i}}{\\sum\\limits^{k}_{j=1} e^{\\theta^{j} \\cdot x^i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01c107",
   "metadata": {},
   "source": [
    "**Equation 4-21: Softmax Regression classifier prediction**\n",
    "\n",
    "$\n",
    "\\hat{y} = \\underset{k}{\\operatorname{argmax}} \\, \\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\underset{k}{\\operatorname{argmax}} \\, s_k(\\mathbf{x}) = \\underset{k}{\\operatorname{argmax}} \\, \\left( ({\\boldsymbol{\\theta}^{(k)}})^T \\mathbf{x} \\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6919430",
   "metadata": {},
   "source": [
    "**Equation 4-22: Cross entropy cost function**\n",
    "\n",
    "$\n",
    "J(\\boldsymbol{\\Theta}) = - \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\sum\\limits_{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19267fe1",
   "metadata": {},
   "source": [
    "**Cross entropy between two discrete probability distributions $p$ and $q$ (page 141):**\n",
    "$ H(p, q) = -\\sum\\limits_{x}p(x) \\log q(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23baaf8c",
   "metadata": {},
   "source": [
    "**Equation 4-23: Cross entropy gradient vector for class _k_**\n",
    "\n",
    "$\n",
    "\\nabla_{\\boldsymbol{\\theta}^{(k)}} \\, J(\\boldsymbol{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cff51f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### API (sklearn.linear_model.LogisticRegression):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c582f43",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "- [sklearn.linear_model.SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc985e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python \n",
    "LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "```\n",
    "\n",
    "- `dual`: Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer `dual=False` when `n_samples > n_features`.\n",
    "- `C`: Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "- `multi_class` ({`‘auto’`, `‘ovr’`, `‘multinomial’`}, `default=’auto’`): If the option chosen is `‘ovr’`, then a binary problem is fit for each label. For `‘multinomial’` the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. `‘multinomial’` is unavailable when `solver=’liblinear’`. `‘auto’` selects `‘ovr’` if the data is binary, or if `solver=’liblinear’`, and otherwise selects `‘multinomial’`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b126c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "|Attributes|Methods|\n",
    "|----|----|\n",
    "|`clf.classes_`| `decision_function(...)`|\n",
    "|`clf.coef_`| `densify(...)`|\n",
    "|`clf.intercept_`| `fit(...)`|\n",
    "|`clf.n_iter_`| `get_params(...)`|\n",
    "|   |`predict(...)`|\n",
    "|   |`predict_log_proba(...)`|\n",
    "|   |`predict_proba(...)`|\n",
    "|   |`score(...)`|\n",
    "|   |`set_params(...)`|\n",
    "|   |`sparsif(...)`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83726f96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "class sklearn.linear_model.SGDClassifier(loss='log', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n",
    "```\n",
    "\n",
    "- `alpha=0.0001`: Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when set to `learning_rate` is set to `‘optimal’`.\n",
    "\n",
    "- `epsilon=0.1`: Epsilon in the epsilon-insensitive loss functions; only if loss is `‘huber’`, `‘epsilon_insensitive’`, or `‘squared_epsilon_insensitive’`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6de9599c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dir(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f05a96b3",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14cdb8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e568e19",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5b319",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "- **Number of Instances**: 150 (50 in each of three classes)\n",
    "- **Number of Features**: 4 numeric, predictive attributes and the class\n",
    "- **Feature Information**:\n",
    "    - sepal length in cm\n",
    "    - sepal width in cm\n",
    "    - petal length in cm\n",
    "    - petal width in cm\n",
    "- **class**:\n",
    "    - Iris-Setosa\n",
    "    - Iris-Versicolour\n",
    "    - Iris-Virginica\n",
    "\n",
    "- `iris.data`, `iris.target`, `iris.target_names`, `iris.DSCER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1d66faff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iris = ds.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccc64176",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2\n",
       "5  5.4  3.9  1.7  0.4\n",
       "6  4.6  3.4  1.4  0.3\n",
       "7  5.0  3.4  1.5  0.2\n",
       "8  4.4  2.9  1.4  0.2\n",
       "9  4.9  3.1  1.5  0.1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "df = pd.DataFrame(X); df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b1d695b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalize = sk.preprocessing.StandardScaler().fit(X).transform(iris.data)\n",
    "X[0:5], y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43843969",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalize, iris.target, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aca3c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac70dbda",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c08d121",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "\n",
      "[[-0.929  0.916 -1.371 -1.242]\n",
      " [ 0.574 -0.592 -0.344 -0.61 ]\n",
      " [ 0.355 -0.324  1.716  1.853]]\n",
      "\n",
      "[-0.116  1.233 -1.117]\n",
      "\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_, clf.coef_, clf.intercept_, clf.n_iter_, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39333851",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4078522e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.517e-09, 3.325e-04, 9.997e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = randint(0, len(X))\n",
    "clf.predict_proba(X[idx:idx+1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cc562",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2057997",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)\n",
    "clf.predict_proba(X)[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1aca0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc8a362b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04451536",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_cm = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues)\n",
    "display_cm.figure_.set_size_inches((8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f390ac3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_cm.figure_.set_size_inches((8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c42df51",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# help(display_cm.figure_.set_size_inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53c2831c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  0,  0],\n",
       "       [ 0, 31,  2],\n",
       "       [ 0,  1, 20]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_cm.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "687bc272",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       0.97      0.94      0.95        33\n",
      "           2       0.91      0.95      0.93        21\n",
      "\n",
      "    accuracy                           0.96        75\n",
      "   macro avg       0.96      0.96      0.96        75\n",
      "weighted avg       0.96      0.96      0.96        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bc0f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e0c37c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Multi-class Logistic Regressio (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b69e2f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iris = ds.load_iris()\n",
    "# iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba53f63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86af585",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2\n",
       "5           5.4          3.9           1.7          0.4\n",
       "6           4.6          3.4           1.4          0.3\n",
       "7           5.0          3.4           1.5          0.2\n",
       "8           4.4          2.9           1.4          0.2\n",
       "9           4.9          3.1           1.5          0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = ds.load_iris(return_X_y=True)\n",
    "df = pd.DataFrame(X, columns=['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']); df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "887b78d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.143, -0.132, -1.34 , -1.315])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88180b74",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.901,  1.019, -1.34 , -1.315],\n",
       "       [-1.143, -0.132, -1.34 , -1.315],\n",
       "       [-1.385,  0.328, -1.397, -1.315],\n",
       "       [-1.507,  0.098, -1.283, -1.315],\n",
       "       [-1.022,  1.249, -1.34 , -1.315]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ecb194b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999994"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "334b4f3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b64af43a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "\n",
      "[[-1.074  1.16  -1.931 -1.812]\n",
      " [ 0.588 -0.362 -0.363 -0.826]\n",
      " [ 0.486 -0.798  2.294  2.638]]\n",
      "\n",
      "[-0.205  2.075 -1.87 ]\n",
      "\n",
      "[25]\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_, clf.coef_, clf.intercept_, clf.n_iter_, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "83f4911c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yhat_ = clf.predict(X[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ec33e784",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.891e-01, 1.088e-02, 1.727e-07]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(X))\n",
    "clf.predict_proba(X[idx:idx+1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "442c5444",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)\n",
    "clf.predict_proba(X)[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "224280a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-f38cc4eab316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhat_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'yhat' is not defined"
     ]
    }
   ],
   "source": [
    "yhat_1 = yhat == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "67611f11",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yhat_prob = clf.predict_proba(X); yhat_prob[yhat_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeeec3a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "# log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272b140",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Interview Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
