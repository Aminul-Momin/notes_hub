-   [FastAPI](https://fastapi.tiangolo.com/)
-   [Templates](https://fastapi.tiangolo.com/advanced/templates/)

---

```python
# ============================================================================
# /app/routers/*.py
from fastapi import FastAPI, Response, status, HTTPException, Depends, APIRouter
from fastapi.security.oauth2 import OAuth2PasswordRequestForm

from sqlalchemy import Column, Integer, String, Boolean, ForeignKey
from sqlalchemy import func, insert, select, update, delete

from sqlalchemy.orm import relationship, Session
from sqlalchemy.sql.expression import text
from sqlalchemy.sql.sqltypes import TIMESTAMP
from sqlalchemy.ext.declarative import declarative_base

from .. import database, schemas, models, utils, oauth2
from ..database import get_db

# ============================================================================
# /app/models/*.py
from sqlalchemy import INTEGER, VARCHAR, Column, TIMESTAMP, func

# ============================================================================
# /app/schemas/*.py
from pydantic import BaseModel, constr

```

---

<details><summary style="font-size:20px;color:Orange;text-align:left">Alembic</summary>

-   [Alembic’s documentation](https://alembic.sqlalchemy.org/en/latest/)
-   [Tutorial: Intro to Database Migrations with Alembic](https://www.youtube.com/watch?v=SdcH6IEi6nE)

-   `Alembic`: In the context of Python, Alembic is an open-source database migration tool that is commonly used with SQLAlchemy, a popular Object Relational Mapping (ORM) library. Alembic helps developers manage database schema changes and versioning in a systematic and organized way.
-   `Key Features and Concepts`:

    -   `Database Migrations`: Alembic allows developers to create and manage database migrations, which are scripts that define changes to the database schema over time. These migrations capture alterations such as adding new tables, modifying columns, or creating indexes.
    -   `Versioning`: Alembic maintains a version history of the database schema by creating and tracking migration files. Each migration file corresponds to a specific version of the schema. This versioning ensures that database changes can be applied in a controlled and predictable manner.
    -   `Command-Line Interface`: Alembic provides a command-line interface (CLI) that allows developers to create, apply, and manage migrations using simple commands. This interface simplifies the process of creating and managing migration scripts.
    -   `Migration Scripts`: Migration scripts are Python scripts generated by Alembic that define database changes. These scripts include instructions to alter the schema, such as creating tables, modifying columns, and adding constraints.
    -   `Migration Upgrades and Downgrades`: Alembic supports both upgrade and downgrade migrations. An upgrade migrates the database schema to a higher version, while a downgrade reverts the schema to a lower version. This helps in rolling back changes if necessary.
    -   `Automated Generation`: Alembic can automatically generate migration scripts based on the changes made to the SQLAlchemy models. It analyzes the differences between the current database schema and the desired schema based on the models and generates migration scripts accordingly.
    -   `Customization`: Developers can customize migration scripts by adding custom SQL commands or Python code to perform complex migrations that may not be automatically detected.
    -   `Integration with SQLAlchemy`: Alembic is designed to work seamlessly with SQLAlchemy, allowing developers to manage database schema changes alongside their SQLAlchemy models.
    -   `Version Control Integration`: Migration scripts can be stored in version control systems (e.g., Git) along with the application code, enabling collaborative development and ensuring a history of schema changes.
    -   `Cross-Database Support`: Alembic supports multiple database backends, enabling developers to work with different database systems while using the same migration tool.
    -   `Documentation and Support`: Alembic provides comprehensive documentation and a supportive community, making it easier for developers to learn and use the tool effectively.

-   Conclusion: Alembic is a powerful and versatile tool for managing database migrations in Python projects. It helps developers maintain a structured approach to evolving the database schema over time, while its integration with SQLAlchemy ensures consistency between application code and the database structure.

<details><summary style="font-size:18px;color:magenta;text-align:left">Data Migration with Alembic</summary>

-   `$ pip install alembic`
-   `$ alembic --help`

#### Configure Alembic

-   [Configuration](https://alembic.sqlalchemy.org/en/latest/api/config.html)

-   `$ alembic init alembic` → Create Alembic directory by the name of 'alembic'

```python
# alembic/env.py
from app.models import Base
...

# Overwrite the the value for "sqlalchemy.url" in 'alembic.ini' file
config.set_main_optin("sqlalchemy.url", "sqlite:///site.db")

target_metadata = Base.metadata
```

```ini
# alembic.ini
sqlalchemy.url = 'sqlite:///site.db'
```

#### Migration Process (Create table)

-   [DDL Internals](https://alembic.sqlalchemy.org/en/latest/api/ddl.html)

-   `$ alembic revision --help`
-   `$ alembic revision -m "Create user table"`

```python
# alembic/version/*revision*.py
def upgrade():
    op.create_table(
        'users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(), nullable=False),
        sa.Column('password', sa.String(), nullable=False)
    )
    pass


def downgrade():
    op.drop_table('users')
    pass
```

-   `$ alembic current`
-   `$ alembic upgrade e0afb679c9cb`

#### Migration Process (Add a Column to an existing table)

-   `$ alembic revision -m "Add 'created_at' column to user table"`

```python
def upgrade():
    op.add_column(
        'users',
        sa.Column('created_at', sa.TIMESTAMP, nullable=False, server_default=sa.func.now())
    )
    pass


def downgrade():
    op.drop_column('users', 'created_at')
    pass
```

-   `$ alembic --help`
-   `$ alembic current`
-   `$ alembic heads`
-   `$ alembic upgrade heads`

#### Migration Process (Delete a Column from an existing table)

-   `$ alembic downgrade -1`
-   `$ `
-   `$ `
-   `$ `

</details>
</details>

---

<details><summary style="font-size:20px;color:Orange;text-align:left">Pydentic</summary>

-   [Documentation](https://docs.pydantic.dev/latest/)
-   [API Documentation](https://docs.pydantic.dev/latest/api/base_model/)

-   `Pydentic`:Pydantic is a Python library that provides data validation and settings management using Python type annotations. It's particularly useful for validating and parsing data, such as JSON payloads or configuration settings, based on defined models with type hints and validation rules. Pydantic helps ensure data consistency, integrity, and accurate parsing while working with complex data structures.

-   `Key features of Pydantic`:

    -   `Data Validation`: Pydantic uses type hints and validation rules to validate data, ensuring that it conforms to the expected structure and constraints.

    -   `Parsing`: It can automatically parse and convert incoming data, such as JSON, into Python objects that adhere to the defined model.

    -   `Settings Management`: Pydantic is commonly used to manage application settings by defining a settings model with default values, types, and validation rules.

    -   `Customization`: It allows customization of validation rules, error messages, and default values for different fields.

    -   `Complex Types`: Pydantic supports complex data types, including nested models, lists, dictionaries, and more.

    -   `API Request and Response Validation`: It's often used in web applications to validate incoming API requests and format API responses.

    -   `Data Serialization`: Pydantic can serialize data back to JSON or other formats based on the defined model.

    -   `Type Conversion`: It performs automatic type conversion for basic data types, ensuring data consistency.

    -   `Integration with Frameworks`: Pydantic can be integrated with web frameworks like FastAPI to streamline input validation and serialization.

-   Here's a simple example of using Pydantic to define a data model for validating and parsing user data:

    ```python
    from pydantic import BaseModel

    class User(BaseModel):
        username: str
        email: str

    #======================
    data = {
        "username": "john_doe",
        "email": "john@example.com"
    }

    user = User(**data)  # Validation and parsing
    print(user.username)  # Output: john_doe
    ```

-   `Conclusion`: Pydantic is a valuable library in the Python ecosystem that ensures data integrity, simplifies data validation, and streamlines the process of parsing and working with structured data. It's commonly used in various scenarios, including web applications, configuration management, and data transformation.

### Pydentic Models vs Database Models

In FastAPI, Pydantic models and data models serve different purposes but are closely related. They are both integral to defining and validating data in your web application, but they are used in different contexts.

-   `Pydantic Models`:

    -   `Purpose`: Pydantic models are primarily used for request and response data validation and serialization. They allow you to define the expected structure and data types of incoming JSON data (request bodies) and outgoing JSON data (response payloads).

    -   `Validation`: Pydantic models automatically validate incoming JSON data against the defined structure, ensuring that it adheres to your expectations. If the data doesn't match the model's schema, FastAPI will raise a validation error and return a meaningful error response.

    -   `Usage`: Pydantic models are commonly used as function parameters to automatically parse and validate incoming data in request handlers. They are also used to declare response models to specify the structure of data returned by API endpoints.

    -   `Example`:

        ```python

        from pydantic import BaseModel

        class Item(BaseModel):
            name: str
            price: float

        @app.post("/items/")
        async def create_item(item: Item):
            # `item` is automatically validated against the `Item` model.
            # If the data doesn't match the structure, FastAPI raises an error.
            # Otherwise, you can work with the validated data.
            return {"name": item.name, "price": item.price}
        ```

-   `Data Models (Database Models)`:

    -   `Purpose`: Data models, also known as database models, are used to define the structure of data that will be stored in a database. They represent the tables, fields, and relationships within your database.

    -   `Validation`: While data models in FastAPI don't perform data validation in the same way as Pydantic models, they often rely on ORM (Object-Relational Mapping) libraries like SQLAlchemy to define data constraints and relationships at the database level.

    -   `Usage`: Data models are typically used with database libraries to create and query the database. ORM libraries allow you to map data models to database tables, making it easier to work with database records in your application.

    -   Example (using SQLAlchemy):

        ```python

        from sqlalchemy import Column, Integer, String
        from sqlalchemy.ext.declarative import declarative_base

        Base = declarative_base()

        class Item(Base):
            __tablename__ = "items"

            id = Column(Integer, primary_key=True, index=True)
            name = Column(String, index=True)
            price = Column(Float)
        ```

-   `Note`: While Pydantic models and data models serve different purposes, they can work together. You can use Pydantic models to validate incoming data, then convert and save it to your database using data models.

In summary, Pydantic models are primarily used for request and response data validation in FastAPI, while data models are used to define the structure of data stored in databases. Both play crucial roles in building robust and data-validating web applications with FastAPI, especially when used in combination.

</details>

---

<details><summary style="font-size:20px;color:Orange;text-align:left">SQLAlchemy</summary>

-   [FastAPI - using SQLAlchemy for DB queries [part - 1]](https://www.youtube.com/watch?v=6RrwKDGKcxM)

-   [SQLAlchemy Datatype Objects](https://docs.sqlalchemy.org/en/20/core/types.html)
-   [class sqlalchemy.schema.Column](https://docs.sqlalchemy.org/en/20/core/metadata.html#sqlalchemy.schema.Column)
-   [Field Data Types](https://docs.sqlalchemy.org/en/20/core/type_basics.html)

-   Architecture:

    -   `SQLAlchemy Library`: At the top level, SQLAlchemy is a Python library that provides tools for working with relational databases.

    -   `Core Components`:

        -   The Core provides a low-level abstraction over databases and SQL. It includes components for constructing and executing SQL expressions, managing connections, transactions, and more.
        -   The Core components include elements for constructing SQL expressions and interacting with databases.

        -   `SQL Expression Language`: This part of the Core allows you to define SQL statements using Python objects and methods. It includes clauses, operators, functions, and more.

        -   `Engine`: The Engine is responsible for managing database connections and executing SQL statements. It includes connection pooling, transaction management, and supports multiple database dialects.

    -   `ORM Components`:

        -   The ORM layer builds on top of the Core and provides a high-level interface for mapping Python classes to database tables. It includes components for defining and querying models, relationships, sessions, and transactions.
        -   The ORM layer provides a higher-level interface for working with databases using Python classes and objects.

        -   `Model Classes`: Model classes represent Python objects that map to database tables. They define attributes, relationships, and metadata.

        -   `Mapping Configuration`: The mapping configuration specifies how Python classes and attributes are mapped to database tables and columns.

        -   `Session`: The Session class manages interactions with the database, including creating, updating, and deleting records. It also provides transactional capabilities.

        -   `Query API`: The Query class allows you to build and execute database queries using Python methods and attributes. It supports filtering, joining, ordering, and aggregating data.

        -   `Relationships`: SQLAlchemy supports defining relationships between model classes, such as one-to-one, one-to-many, and many-to-many relationships.

    -   `Metadata and Reflection`: Metadata represents the structure of the database and is used to define tables, constraints, and other schema elements. Reflection allows you to introspect existing databases to automatically generate model classes.

    -   `SQL Dialects`: SQLAlchemy supports multiple database backends by generating appropriate SQL syntax for each dialect.

    -   `Extensions and Plugins`: SQLAlchemy's modular architecture allows for extensions and plugins to add additional functionality, such as validation, caching, and more.

    -   In summary, the SQLAlchemy architecture consists of the Core and ORM layers. The Core provides tools for constructing and executing SQL expressions, while the ORM layer provides a high-level interface for mapping Python classes to database tables, managing sessions, and querying data. The architecture's modular design and well-defined components make it a powerful and flexible library for working with relational databases in Python.

### How to perform `JOIN` operation?

-   `Using join() Method (as previously shown)`:

    -   This is the most straightforward way to perform JOIN operations in SQLAlchemy.
    -   It allows you to specify the join condition explicitly.

    ```python

    # Perform an INNER JOIN between User and Address models
    query = session.query(User, Address).join(Address, User.user_id == Address.user_id)

    # Fetch the result of the join operation
    results = query.all()

    # Print the results
    for user, address in results:
        print(f"User: {user.name}, Address: {address.street}, {address.city}")
    ```

-   `Using Relationship Attributes`:

    -   If you have defined relationships between your SQLAlchemy models (e.g., using relationship()), you can access related data directly through these relationships.

    ```python
    # Assuming a one-to-many relationship between User and Address
    user = session.query(User).filter_by(username='john').first()
    addresses = user.addresses
    ```

    -   SQLAlchemy will automatically generate the appropriate JOIN query behind the scenes.

-   `Using select_from() Method`:

    -   You can use the `select_from()` method to specify the source tables for your query explicitly.

    ```python
    query = session.query(User, Address).select_from(User).join(Address, User.user_id == Address.user_id)
    ```

-   `Using Aliases`:

    -   You can create aliases for your tables and perform joins with aliases, which can be useful for complex queries.

    ```python
    from sqlalchemy.orm import aliased

    user_alias = aliased(User)
    address_alias = aliased(Address)

    query = session.query(User, Address).\
        join(address_alias, User.user_id == address_alias.user_id)
    ```

-   `Using Raw SQL`:

    -   In some cases, you may need to use raw SQL for complex queries.

    ```python
    from sqlalchemy.sql import text

    sql = text("SELECT * FROM user JOIN address ON user.user_id = address.user_id")
    result = session.execute(sql)
    ```

    -   Use this approach with caution, as it may not be as database-agnostic as other SQLAlchemy methods.

---

<details><summary style="font-size:20px;color:Orange;text-align:left">SQLAlchemy query methods</summary>

-   `query()`: This method is the starting point for creating a query.

    ```python
    from sqlalchemy import create_engine, Column, Integer, String
    from sqlalchemy.ext.declarative import declarative_base
    from sqlalchemy.orm import sessionmaker

    # Define the model
    Base = declarative_base()

    class User(Base):
        __tablename__ = 'users'
        id = Column(Integer, primary_key=True)
        username = Column(String)
        email = Column(String)

    # Create the engine and session
    engine = create_engine('sqlite:///example.db')
    Session = sessionmaker(bind=engine)
    session = Session()

    # Example of using query methods on model object
    user = session.query(User).filter_by(username='alice').first()
    print(user.username, user.email)

    session.close()
    ```

-   `filter()`: Adds filtering conditions to the query.

    ```python
    # Filtering users with age greater than 25
    users = session.query(User).filter(User.age > 25).all()
    ```

-   `filter_by()`: Similar to filter(), but uses keyword arguments for filtering conditions.

    ```python
    # Filtering users with name 'Alice'
    users = session.query(User).filter_by(name='Alice').all()
    ```

-   `join()`: Creates a SQL JOIN operation between tables.

    ```python
    from sqlalchemy.orm import joinedload

    # Joining User and Address tables
    users_with_addresses = session.query(User).join(Address).all()
    ```

-   `outerjoin()`: Creates an OUTER JOIN operation between tables.

    ```python
    # Outer joining User and Address tables
    users_with_optional_addresses = session.query(User).outerjoin(Address).all()
    ```

-   `group_by()`: Groups the results based on specified columns.

    ```python
    from sqlalchemy import func

    # Grouping users by age and counting
    age_group_counts = session.query(User.age, func.count()).group_by(User.age).all()
    ```

-   `order_by()`: Specifies the order in which the results should be sorted.

    ```python
    # Ordering users by name in descending order
    users_ordered_by_name = session.query(User).order_by(User.name.desc()).all()
    ```

-   `limit()`: Limits the number of results returned by the query.

    ```python
    # Limiting to retrieve only 5 users
    limited_users = session.query(User).limit(5).all()
    ```

-   `offset()`: Skips a certain number of results before starting to fetch.

    ```python
    # Retrieving users after skipping the first 10
    users_after_offset = session.query(User).offset(10).all()
    ```

-   `distinct()`: Applies the DISTINCT keyword to the query.

    ```python
    # Retrieving distinct age values
    distinct_ages = session.query(User.age).distinct().all()
    ```

-   `count()`: Returns the count of rows matching the query.

    ```python
    # Counting the number of users
    user_count = session.query(User).count()
    ```

-   `first()`: Returns the first result of the query.

    ```python
    # Retrieving the first user
    first_user = session.query(User).first()
    ```

-   `all()`: Returns all results of the query.

    ```python
    # Retrieving all users
    all_users = session.query(User).all()
    ```

-   `scalar()`: Returns the first column of the first result as a scalar value.

    ```python
    # Retrieving the scalar value of the first user's age
    first_user_age = session.query(User.age).first()
    ```

-   `exists()`: Returns a boolean indicating whether any results exist for the query.

    ```python
    # Checking if there are any users with age greater than 30
    users_exist = session.query(User).filter(User.age > 30).exists()
    ```

-   `subquery()`: Returns a subquery representing the current query.

    ```python
    # Using a subquery to retrieve addresses of users older than 25
    subq = session.query(Address.user_id).filter(User.age > 25).subquery()
    addresses = session.query(Address).filter(Address.user_id.in_(subq)).all()
    ```

-   `from_self()`: Returns a new Query object with the same options as the current query.

    ```python
    # Creating a new query from an existing query
    new_query = session.query(User).from_self()
    ```

-   `get()`: Retrieves a row by its primary key value.

    ```python
    # Retrieving a user by primary key
    user = session.query(User).get(1)
    ```

-   `delete()`: Generates a DELETE statement based on the query and deletes matching rows.

    ```python
    # Deleting users with age less than 25
    session.query(User).filter(User.age < 25).delete()
    ```

-   `update()`: Generates an UPDATE statement based on the query and updates matching rows.

    ```python
    # Updating age of users named 'Alice'
    session.query(User).filter_by(name='Alice').update({'age': 28})
    ```

-   `union()`: Creates a union of two or more queries.

    ```python
    # Creating a union of two queries
    union_query = session.query(User).filter(User.age < 30).union(session.query(User).filter(User.age > 40))
    ```

-   `intersect()`: Creates an intersection of two or more queries.

    ```python
    # Creating an intersection of two queries
    intersection_query = session.query(User).filter(User.age < 30).intersect(session.query(User).filter(User.age > 20))
    ```

-   `except_()`: Creates a difference between two queries.

    ```python
    # Creating a difference between two queries
    difference_query = session.query(User).filter(User.age < 30).except_(session.query(User).filter(User.age < 25))
    ```

-   These are some of the many query methods provided by SQLAlchemy's Query API. Keep in mind that this is a simplified demonstration, and you can combine and customize these methods to build complex and efficient queries for your database interactions. For more comprehensive information and examples, refer to the official SQLAlchemy documentation.

</details>
</details>

---

<details><summary style="font-size:20px;color:Orange;text-align:left">SQLAlchemy query methods</summary>

-   <b style="color:magenta">What is FastAPI?</b>

    -   FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.

-   <b style="color:magenta">How does FastAPI differ from traditional web frameworks like Flask or Django?</b>

    -   FastAPI is designed for building APIs with automatic OpenAPI and JSON Schema documentation, automatic validation using Python type hints, and high performance through asynchronous request handling.

-   <b style="color:magenta">Explain asynchronous programming in FastAPI.</b>

    -   FastAPI uses Python's async and await syntax for asynchronous programming. It allows handling concurrent requests efficiently using asynchronous frameworks like Starlette and Uvicorn.

-   <b style="color:magenta">What is dependency injection in FastAPI?</b>

    -   Dependency injection in FastAPI refers to the automatic injection of dependencies (such as database connections or external services) into route functions or other parts of the application.

-   <b style="color:magenta">How does FastAPI handle request validation?</b>

    -   FastAPI uses Python type hints for automatic request validation. Input data is validated against these type hints, and validation errors are automatically handled and documented.

-   <b style="color:magenta">Explain path parameters and query parameters in FastAPI.</b>

    -   Path parameters are part of the URL path (e.g., /items/{item_id}). Query parameters are appended to the URL and are optional (e.g., /items?skip=10&limit=5). FastAPI can automatically parse and validate these parameters.

-   <b style="color:magenta">What is Pydantic, and how is it used in FastAPI?</b>

    -   Pydantic is a data validation library that is used in FastAPI to define data models with Python type hints. It is used for request and response validation, as well as for automatic API documentation generation.

-   <b style="color:magenta">Explain the purpose of FastAPI's BackgroundTasks class.</b>

    -   BackgroundTasks in FastAPI allows you to perform background tasks (e.g., sending emails) after a response has been delivered to the client. It ensures a faster response to the client.

-   <b style="color:magenta">What is OAuth2 authentication, and how is it implemented in FastAPI?</b>

    -   OAuth2 is a protocol for authorization, and FastAPI includes OAuth2 authentication features. It allows securing API routes with OAuth2-based token authentication, such as JWT (JSON Web Tokens).

-   <b style="color:magenta">How does FastAPI handle file uploads?</b>

    -   FastAPI supports file uploads using the UploadFile class. It allows handling file uploads in forms and validating file properties, such as size and content type.

-   <b style="color:magenta">What is FastAPI's automatic documentation feature based on?</b>

    -   FastAPI's automatic documentation is generated based on the OpenAPI standard and JSON Schema. It provides interactive documentation that allows users to explore and test the API.

-   <b style="color:magenta">Explain FastAPI's dependency injection system.</b>

    -   FastAPI's dependency injection system automatically injects dependencies into route functions based on function parameters. Dependencies are resolved at runtime, and they can be reused across multiple routes.

-   <b style="color:magenta">How does FastAPI handle CORS (Cross-Origin Resource Sharing)?</b>

    -   FastAPI includes middleware for handling CORS. It allows specifying which origins are allowed to access the API and which HTTP methods are allowed for cross-origin requests.

-   <b style="color:magenta">What is FastAPI's WebSocket support?</b>

    -   FastAPI provides native support for WebSocket communication. It allows handling WebSocket connections in a similar way to handling HTTP requests.

-   <b style="color:magenta">How can you handle background tasks in FastAPI?</b>

    -   Background tasks in FastAPI can be handled using the BackgroundTasks class. You can add tasks to it within a route, and they will be executed after the response is sent to the client.

-   <b style="color:magenta">Explain FastAPI's dependency injection for database connections.</b>

    -   FastAPI allows dependency injection for database connections by defining a dependency on a route function. The connection can be reused across multiple routes, and FastAPI takes care of its lifecycle.

-   <b style="color:magenta">What is FastAPI's testing framework?</b>

    -   FastAPI has a built-in testing framework that allows testing API routes using the TestClient class. It provides methods for making requests and asserting responses.

-   <b style="color:magenta">How can you handle cookies in FastAPI?</b>

    -   FastAPI provides a Cookie class for handling cookies. Cookies can be both read and set in API routes, and FastAPI automatically validates and documents their use.

-   <b style="color:magenta">What is FastAPI's Depends function?</b>

    -   Depends is a decorator in FastAPI that is used for declaring dependencies on route functions. It allows specifying which dependencies should be injected into the route.

-   <b style="color:magenta">Explain FastAPI's support for request and response models.</b>

    -   FastAPI supports request and response models using Pydantic. Request models are used for validating incoming data, and response models are used for defining the structure of the API response.

-   <b style="color:magenta">How does FastAPI handle API versioning?</b>

    -   FastAPI supports API versioning by including the version in the URL or as a header. It allows maintaining multiple versions of the API simultaneously.

-   <b style="color:magenta">What is FastAPI's HTTPException class used for?</b>

    -   HTTPException in FastAPI is used for raising HTTP exceptions with specific status codes. It allows customizing the exception response, including headers and JSON content.

-   <b style="color:magenta">Explain FastAPI's automatic dependency injection for OAuth2 authentication.</b>

    -   FastAPI provides automatic dependency injection for OAuth2 authentication by using the Depends decorator. It allows securing routes with OAuth2 token authentication.

-   <b style="color:magenta">How can you handle response headers in FastAPI?</b>

    -   FastAPI allows handling response headers using the Response class. Headers can be set or modified within a route function.

-   <b style="color:magenta">What is FastAPI's Form class used for?</b>

    -   The Form class in FastAPI is used for handling form data in requests. It allows specifying form fields with validation and automatic documentation.

-   <b style="color:magenta">Explain FastAPI's APIRouter class.</b>

    -   APIRouter in FastAPI is used for organizing and grouping routes. It allows creating modular route structures that can be included in the main FastAPI application.

-   <b style="color:magenta">How does FastAPI handle dependency validation failures?</b>

    -   FastAPI automatically handles dependency validation failures and returns an error response with details about the validation error, including JSON content and status codes.

-   <b style="color:magenta">What is FastAPI's Body class used for?</b>

    -   The Body class in FastAPI is used for handling request bodies. It allows specifying the request body model and its properties for validation.

-   <b style="color:magenta">How can you deploy a FastAPI application?</b>

    -   FastAPI applications can be deployed using ASGI servers such as Uvicorn or Hypercorn. They can be run directly or behind a proxy server like Nginx or Traef

</details>
